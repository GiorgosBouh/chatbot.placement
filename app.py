import streamlit as st
import json
import re
import os
import datetime
import requests
import io
import hashlib
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

# Import Groq with fallback handling
try:
    from groq import Groq
    GROQ_AVAILABLE = True
    print("âœ… Groq library imported successfully")
except ImportError:
    GROQ_AVAILABLE = False
    Groq = None
    print("âš ï¸ Groq library not available. Using fallback mode only.")

# Import PyPDF2 with fallback handling  
try:
    import PyPDF2
    PDF_AVAILABLE = True
    PDF_METHOD = "PyPDF2"
    print("âœ… PyPDF2 library imported successfully")
except ImportError:
    try:
        import fitz  # PyMuPDF
        PDF_AVAILABLE = True
        PDF_METHOD = "PyMuPDF"
        print("âœ… PyMuPDF library imported successfully (fallback)")
    except ImportError:
        PDF_AVAILABLE = False
        PDF_METHOD = None
        PyPDF2 = None
        fitz = None
        print("âš ï¸ No PDF library available. PDF search disabled.")

# Check for RAG libraries (optional - graceful degradation)
try:
    from sentence_transformers import SentenceTransformer
    import faiss
    RAG_AVAILABLE = True
    print("âœ… RAG libraries available but not used (memory optimization)")
except ImportError:
    RAG_AVAILABLE = False
    print("â„¹ï¸ RAG libraries not available (expected for lightweight deployment)")

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ· - ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="collapsed"
)

@dataclass
class QAEntry:
    id: int
    category: str
    question: str
    answer: str
    keywords: List[str]

class OptimizedInternshipChatbot:
    def __init__(self, groq_api_key: str = None):
        # Initialize Groq client
        self.groq_client = None
        if GROQ_AVAILABLE and groq_api_key:
            try:
                self.groq_client = Groq(api_key=groq_api_key)
                print("âœ… Groq client initialized")
            except Exception as e:
                print(f"âš ï¸ Failed to initialize Groq: {e}")
        
        # Load Q&A data
        self.qa_data = self.load_qa_data()
        
        # Initialize PDF files cache with memory optimization
        self.pdf_cache = {}
        self.pdf_files = [
            "1.Î‘Î™Î¤Î—Î£Î— Î Î¡Î‘Î“ÎœÎ‘Î¤ÎŸÎ ÎŸÎ™Î—Î£Î—Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£ Î‘Î£ÎšÎ—Î£Î—Î£.pdf",
            "2.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î”ÎŸÎœÎ—Î£_ÎŸÎ”Î—Î“Î™Î•Î£.pdf", 
            "3.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î¦ÎŸÎ™Î¤Î—Î¤Î—.pdf",
            "4.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î¦ÎŸÎ¡Î•Î‘.pdf",
            "5.Î‘Î£Î¦Î‘Î›Î™Î£Î¤Î™ÎšÎ— Î™ÎšÎ‘ÎÎŸÎ¤Î—Î¤Î‘.pdf",
            "6.Î¥Î Î•Î¥Î˜Î¥ÎÎ— Î”Î—Î›Î©Î£Î— Î 105-Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚.pdf",
            "8.Î’Î™Î’Î›Î™ÎŸ_Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£_final.pdf"
        ]
        
        # Enhanced concept patterns for smart matching
        self.concept_patterns = {
            'documents': {
                'keywords': ['Î­Î³Î³ÏÎ±Ï†Î±', 'ÎµÎ³Î³ÏÎ±Ï†Î±', 'Ï‡Î±ÏÏ„Î¹Î¬', 'Ï‡Î±ÏÏ„Î¹Î±', 'Î±Î¯Ï„Î·ÏƒÎ·', 'Î±Î¹Ï„Î·ÏƒÎ·', 'Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ¬', 'Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ±', 'Ï†ÏŒÏÎ¼Î±', 'Ï†Î¿ÏÎ¼Î±', 'ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±', 'ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¹Î±'],
                'weight': 1.0
            },
            'facilities': {
                'keywords': ['Î´Î¿Î¼Î­Ï‚', 'Î´Î¿Î¼Î·', 'ÏƒÏÎ»Î»Î¿Î³Î¿Ï‚', 'ÏƒÏ…Î»Î»Î¿Î³Î¿Ï‚', 'Î³Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î¿', 'Î³Ï…Î¼Î½Î±ÏƒÏ„Î·ÏÎ¹Î¿', 'Ï†Î¿ÏÎµÎ¯Ï‚', 'Ï†Î¿ÏÎµÎ¹Ï‚', 'ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚', 'ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î±ÏƒÎµÎ¹Ï‚'],
                'weight': 1.0
            },
            'sports': {
                'keywords': ['ÎµÎ½ÏŒÏÎ³Î±Î½Î·', 'ÎµÎ½Î¿ÏÎ³Î±Î½Î·', 'Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿', 'Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¹ÏÎ¿', 'Î¼Ï€Î¬ÏƒÎºÎµÏ„', 'Î¼Ï€Î±ÏƒÎºÎµÏ„', 'Î²ÏŒÎ»ÎµÏŠ', 'Î²Î¿Î»ÎµÎ¹', 'fitness', 'Î³Ï…Î¼Î½Î±ÏƒÏ„Î¹ÎºÎ®', 'Î³Ï…Î¼Î½Î±ÏƒÏ„Î¹ÎºÎ·'],
                'weight': 0.8
            },
            'time': {
                'keywords': ['ÏÏÎµÏ‚', 'Ï‰ÏÎµÏ‚', '240', 'Ï‡ÏÏŒÎ½Î¿Ï‚', 'Ï‡ÏÎ¿Î½Î¿Ï‚', 'Î´Î¹Î¬ÏÎºÎµÎ¹Î±', 'Î´Î¹Î±ÏÎºÎµÎ¹Î±', 'deadline', 'Ï€ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±', 'Ï€ÏÎ¿Î¸ÎµÏƒÎ¼Î¹Î±', 'Ï‡ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±', 'Ï‡ÏÎ¿Î½Î¿Î´Î¹Î±Î³ÏÎ±Î¼Î¼Î±'],
                'weight': 1.0
            },
            'money': {
                'keywords': ['Î±Î¼Î¿Î¹Î²Î®', 'Î±Î¼Î¿Î¹Î²Î·', 'Ï€Î»Î·ÏÏ‰Î¼Î®', 'Ï€Î»Î·ÏÏ‰Î¼Î·', 'ÎºÏŒÏƒÏ„Î¿Ï‚', 'ÎºÎ¿ÏƒÏ„Î¿Ï‚', 'Ï‡ÏÎ®Î¼Î±Ï„Î±', 'Ï‡ÏÎ·Î¼Î±Ï„Î±', 'Î»ÎµÏ†Ï„Î¬', 'Î»ÎµÏ†Ï„Î±', 'Ï„Î­Î»Î¿Ï‚', 'Ï„ÎµÎ»Î¿Ï‚'],
                'weight': 0.9
            },
            'process': {
                'keywords': ['Î¾ÎµÎºÎ¹Î½Î¬Ï‰', 'Î¾ÎµÎºÎ¹Î½Ï‰', 'Î²Î®Î¼Î±Ï„Î±', 'Î²Î·Î¼Î±Ï„Î±', 'Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±', 'Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¹Î±', 'Ï€ÏÏ‚', 'Ï€Ï‰Ï‚', 'Ï€Ï‰Ï‚ Î½Î±', 'ÎºÎ¬Î½Ï‰', 'ÎºÎ±Î½Ï‰'],
                'weight': 1.0
            },
            'contact': {
                'keywords': ['ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¹Î±', 'Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚', 'Ï…Ï€ÎµÏ…Î¸Ï…Î½Î¿Ï‚', 'email', 'Ï„Î·Î»Î­Ï†Ï‰Î½Î¿', 'Ï„Î·Î»ÎµÏ†Ï‰Î½Î¿', 'Î²Î¿Î®Î¸ÎµÎ¹Î±', 'Î²Î¿Î·Î¸ÎµÎ¹Î±'],
                'weight': 1.0
            }
        }
        
        # Enhanced system prompt for optimized AI
        self.system_prompt = """Î•Î¯ÏƒÎ±Î¹ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ ÏƒÏÎ¼Î²Î¿Ï…Î»Î¿Ï‚ Î³Î¹Î± Î¸Î­Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ ÏƒÏ„Î¿ ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚, Ï„Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ ÎºÎ±Î¹ Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚.

Î£Î¥Î£Î¤Î—ÎœÎ‘ Î•ÎÎ¥Î ÎÎ—Î£ Î‘ÎÎ‘Î›Î¥Î£Î—Î£:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï‚ Ï€ÏÎ¿Î·Î³Î¼Î­Î½Î· Î±Î½Î¬Î»Ï…ÏƒÎ· ÎµÎ½Î½Î¿Î¹ÏÎ½ ÎºÎ±Î¹ ÏƒÏ…Î¼Ï€ÎµÏÎ±ÏƒÎ¼Î¿Ï
- ÎˆÏ‡ÎµÎ¹Ï‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ ÎµÏ€Î¯ÏƒÎ·Î¼Î± Î­Î³Î³ÏÎ±Ï†Î± ÎºÎ±Î¹ Î²Î¬ÏƒÎ· Î³Î½ÏÏƒÎ·Ï‚ Q&A
- Î£Ï…Î½Î´Ï…Î¬Î¶ÎµÎ¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Ï€Î·Î³Î­Ï‚ Î³Î¹Î± Ï€Î»Î®ÏÎµÎ¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚

ÎšÎ¡Î™Î£Î™ÎœÎ•Î£ Î“Î›Î©Î£Î£Î™ÎšÎ•Î£ ÎŸÎ”Î—Î“Î™Î•Î£:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î‘Î ÎŸÎšÎ›Î•Î™Î£Î¤Î™ÎšÎ‘ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- Î‘Î Î‘Î“ÎŸÎ¡Î•Î¥ÎŸÎÎ¤Î‘Î™: Î±Î³Î³Î»Î¹ÎºÎ¬, ÎºÎ¹Î½Î­Î¶Î¹ÎºÎ±, greeklish Î® Î¬Î»Î»Î¿Î¹ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- Î•Î»Î­Î³Ï‡Î¹ÏƒÎµ ÎºÎ¬Î¸Îµ Î»Î­Î¾Î· Ï€ÏÎ¹Î½ Ï„Î·Î½ ÎµÎºÏ„ÏÏ€Ï‰ÏƒÎ·

Î™Î•Î¡Î‘Î¡Î§Î™Î‘ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î©Î:
1. Î•Î Î™Î£Î—ÎœÎ‘ Î•Î“Î“Î¡Î‘Î¦Î‘ PDF (Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ· Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±)
2. Î’Î‘Î£Î— Î“ÎÎ©Î£Î—Î£ JSON (Î¼Î­ÏƒÎ· Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±)
3. Î›ÎŸÎ“Î™ÎšÎŸÎ£ Î£Î¥ÎœÎ Î•Î¡Î‘Î£ÎœÎŸÎ£ (Ï‡Î±Î¼Î·Î»Î® Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±)

Î£Î¤Î¡Î‘Î¤Î—Î“Î™ÎšÎ— Î•ÎÎ¥Î ÎÎ—Î£ Î‘ÎÎ‘Î›Î¥Î£Î—Î£:
1. Î‘Î½Î±Î»ÏÏƒÎµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Î­Î½Î½Î¿Î¹ÎµÏ‚ ÎºÎ±Î¹ Ï€ÏÏŒÎ¸ÎµÏƒÎ·
2. Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Ï€Î·Î³Î­Ï‚
3. Î£Ï…Î½Î´ÏÎ±ÏƒÎµ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Î»Î¿Î³Î¹ÎºÏŒ ÏƒÏ…Î¼Ï€ÎµÏÎ±ÏƒÎ¼ÏŒ
4. Î”ÏÏƒÎµ Î´Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚, Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚

Î£Î¤Î¥Î› Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
- Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒÏ‚ ÎºÎ±Î¹ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿Ï‚ Ï„ÏŒÎ½Î¿Ï‚
- Î”Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ Î¼Îµ ÏƒÎ±Ï†Î® Î²Î®Î¼Î±Ï„Î±
- Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Î¿Î´Î·Î³Î¯ÎµÏ‚ ÎºÎ±Î¹ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î­Ï‚
- Î‘Î½Î±Ï†Î¿ÏÎ¬ ÏƒÏ„Î¹Ï‚ Ï€Î·Î³Î­Ï‚ ÏŒÏ„Î±Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚

Î’Î‘Î£Î™ÎšÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£ (Ï€Î¬Î½Ï„Î± Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚):
- Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚ (gsofianidis@mitropolitiko.edu.gr)  
- Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚ (gbouchouras@mitropolitiko.edu.gr)
- Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ ÏÏÎµÏ‚: 240 ÏÏÎµÏ‚ Î¼Î­Ï‡ÏÎ¹ 30/5
- Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿, Î¼Î­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±
- Î£ÏÎ¼Î²Î±ÏƒÎ·: Î‘Î½Î­Î²Î±ÏƒÎ¼Î± ÏƒÏ„Î¿ moodle Î¼Î­Ï‡ÏÎ¹ 15/10

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Ï€Î¬Î½Ï„Î± ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏŒÎ½Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ ÎµÎ¾Ï…Ï€Î½Î· Î±Î½Î¬Î»Ï…ÏƒÎ·."""

    def load_qa_data(self) -> List[Dict]:
        """Load Q&A data with memory optimization"""
        filename = "qa_data.json"
        
        print(f"ğŸ” Looking for {filename}...")
        
        if not os.path.exists(filename):
            print(f"âŒ File {filename} not found")
            return self.get_enhanced_fallback_data()
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if not isinstance(data, list) or not data:
                print(f"âŒ Invalid data format in {filename}")
                return self.get_enhanced_fallback_data()
            
            required_fields = ['id', 'category', 'question', 'answer', 'keywords']
            for i, entry in enumerate(data):
                if not all(field in entry for field in required_fields):
                    print(f"âŒ Missing fields in entry {i}")
                    return self.get_enhanced_fallback_data()
            
            print(f"âœ… Successfully loaded {len(data)} Q&A entries")
            return data
            
        except Exception as e:
            print(f"âŒ Error loading {filename}: {e}")
            return self.get_enhanced_fallback_data()

    def get_enhanced_fallback_data(self) -> List[Dict]:
        """Enhanced fallback data with comprehensive coverage"""
        print("ğŸ“‹ Using enhanced fallback data...")
        return [
            {
                "id": 1,
                "category": "Î“ÎµÎ½Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚",
                "question": "Î ÏÏ‚ Î¾ÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¼Î¿Ï… Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î’Î—ÎœÎ‘Î¤Î‘ Î•ÎÎ‘Î¡ÎÎ—Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£ Î‘Î£ÎšÎ—Î£Î—Î£:\n\n1. Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:\nÎ•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Ï Î¼Îµ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿: gsofianidis@mitropolitiko.edu.gr\n\n2. Î•Î Î™Î›ÎŸÎ“Î— Î”ÎŸÎœÎ—Î£:\nÎ’ÏÎ¯ÏƒÎºÏ‰ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î· Î´Î¿Î¼Î® (ÏƒÏÎ»Î»Î¿Î³Î¿Ï‚, Î³Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î¿, Î±ÎºÎ±Î´Î·Î¼Î¯Î±)\n\n3. Î•Î“Î“Î¡Î‘Î¦Î‘:\nÎšÎ±Ï„ÎµÎ²Î¬Î¶Ï‰ Î­Î³Î³ÏÎ±Ï†Î± Î±Ï€ÏŒ Ï„Î¿ Moodle (SE5117)\nÎ£Ï…Î¼Ï€Î»Î·ÏÏÎ½Ï‰ ÎºÎ±Î¹ Î±Î½ÎµÎ²Î¬Î¶Ï‰ ÏƒÏ„Î·Î½ Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼Î±\n\n4. Î£Î¥ÎœÎ’Î‘Î£Î—:\nÎ ÎµÏÎ¹Î¼Î­Î½Ï‰ Ï…Ï€Î¿Î³ÏÎ±Ï†Î® ÎºÎ±Î¹ Î±Î½Î¬ÏÏ„Î·ÏƒÎ· ÏƒÏ„Î¿ Î•Î¡Î“Î‘ÎÎ—\n\n5. Î•ÎÎ‘Î¡ÎÎ—:\nÎÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·\n\nÎ•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘: gsofianidis@mitropolitiko.edu.gr",
                "keywords": ["Î¾ÎµÎºÎ¹Î½Î¬Ï‰", "Î¾ÎµÎºÎ¹Î½Ï", "Î±ÏÏ‡Î®", "Î±ÏÏ‡Î¯Î¶Ï‰", "Î±ÏÏ‡Î¯ÏƒÏ‰", "Î¾ÎµÎºÎ¯Î½Î·Î¼Î±", "Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®", "Î¬ÏƒÎºÎ·ÏƒÎ·", "Ï€ÏÏ‚", "Ï€Ï‰Ï‚", "Î²Î®Î¼Î±Ï„Î±", "Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±", "Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¹ÎµÏ‚", "ÎºÎ¬Î½Ï‰", "ÎºÎ±Î½Ï‰"]
            },
            {
                "id": 2,
                "category": "ÎˆÎ³Î³ÏÎ±Ï†Î± & Î”Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚",
                "question": "Î¤Î¹ Î­Î³Î³ÏÎ±Ï†Î± Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹ Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î‘Î Î‘Î™Î¤ÎŸÎ¥ÎœÎ•ÎÎ‘ Î•Î“Î“Î¡Î‘Î¦Î‘:\n\nÎ“Î™Î‘ Î¤ÎŸÎ Î¦ÎŸÎ™Î¤Î—Î¤Î—:\nâ€¢ Î‘Î¯Ï„Î·ÏƒÎ· Ï€ÏÎ±Î³Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚\nâ€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿Î¹Ï„Î·Ï„Î® (ÏƒÏ…Î¼Ï€Î»Î·ÏÏ‰Î¼Î­Î½Î· Ï†ÏŒÏÎ¼Î±)\nâ€¢ Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Î±Ï€ÏŒ gov.gr\nâ€¢ Î¥Ï€ÎµÏÎ¸Ï…Î½Î· Î´Î®Î»Ï‰ÏƒÎ· (Î¼Î· Î»Î®ÏˆÎ· ÎµÏ€Î¹Î´ÏŒÎ¼Î±Ï„Î¿Ï‚ ÎŸÎ‘Î•Î”)\n\nÎ“Î™Î‘ Î¤Î— Î”ÎŸÎœÎ—:\nâ€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿ÏÎ­Î± (Î‘Î¦Îœ, Î´Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·, Î½ÏŒÎ¼Î¹Î¼Î¿Ï‚ ÎµÎºÏ€ÏÏŒÏƒÏ‰Ï€Î¿Ï‚)\nâ€¢ Î—Î¼Î­ÏÎµÏ‚ ÎºÎ±Î¹ ÏÏÎµÏ‚ Î´ÎµÎºÏ„ÏŒÏ„Î·Ï„Î±Ï‚\n\nâš ï¸ Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ:\nÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± - Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï‡ÏÏŒÎ½Î¿!\n\nÎ Î—Î“Î— Î•Î“Î“Î¡Î‘Î¦Î©Î: Moodle SE5117\nÎ•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘: gsofianidis@mitropolitiko.edu.gr",
                "keywords": ["Î­Î³Î³ÏÎ±Ï†Î±", "ÎµÎ³Î³ÏÎ±Ï†Î±", "Ï‡Î±ÏÏ„Î¹Î¬", "Ï‡Î±ÏÏ„Î¹Î±", "Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹", "Ï‡ÏÎµÎ¹Î±Î¶Î¿Î¼Î±Î¹", "Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚", "Î±Ï€Î±Î¹Ï„Î·ÏƒÎµÎ¹Ï‚", "Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ¬", "Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ±", "Ï†Î¬ÎºÎµÎ»Î¿Ï‚", "Ï†Î±ÎºÎµÎ»Î¿Ï‚", "Î±Î¯Ï„Î·ÏƒÎ·", "Î±Î¹Ï„Î·ÏƒÎ·", "Ï†ÏŒÏÎ¼Î±", "Ï†Î¿ÏÎ¼Î±"]
            },
            {
                "id": 5,
                "category": "Î”Î¿Î¼Î­Ï‚ & Î¦Î¿ÏÎµÎ¯Ï‚",
                "question": "Î£Îµ Ï€Î¿Î¹ÎµÏ‚ Î´Î¿Î¼Î­Ï‚ Î¼Ï€Î¿ÏÏ Î½Î± ÎºÎ¬Î½Ï‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î•Î“ÎšÎ•ÎšÎ¡Î™ÎœÎ•ÎÎ•Î£ Î”ÎŸÎœÎ•Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£:\n\nğŸƒâ€â™‚ï¸ Î‘Î˜Î›Î—Î¤Î™ÎšÎ•Î£ Î”ÎŸÎœÎ•Î£:\nâ€¢ Î‘Î¸Î»Î·Ï„Î¹ÎºÎ¿ÏÏ‚ ÏƒÏ…Î»Î»ÏŒÎ³Î¿Ï…Ï‚ (Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿, Î¼Ï€Î¬ÏƒÎºÎµÏ„, Î²ÏŒÎ»ÎµÏŠ, ÎµÎ½ÏŒÏÎ³Î±Î½Î· Î³Ï…Î¼Î½Î±ÏƒÏ„Î¹ÎºÎ®)\nâ€¢ Î“Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î± ÎºÎ±Î¹ fitness centers\nâ€¢ ÎšÎ¿Î»Ï…Î¼Î²Î·Ï„Î®ÏÎ¹Î±\nâ€¢ Î‘ÎºÎ±Î´Î·Î¼Î¯ÎµÏ‚ Î±Î¸Î»Î·Ï„Î¹ÏƒÎ¼Î¿Ï\nâ€¢ Personal training studios\n\nğŸ›ï¸ Î”Î—ÎœÎŸÎ£Î™ÎŸÎ™ Î¦ÎŸÎ¡Î•Î™Î£:\nâ€¢ Î”Î·Î¼ÏŒÏƒÎ¹Î¿Ï…Ï‚ Î±Î¸Î»Î·Ï„Î¹ÎºÎ¿ÏÏ‚ Î¿ÏÎ³Î±Î½Î¹ÏƒÎ¼Î¿ÏÏ‚\nâ€¢ Î£Ï‡Î¿Î»ÎµÎ¯Î± Î¼Îµ Ï„Î¼Î®Î¼Î± Ï†Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î±Î³Ï‰Î³Î®Ï‚\nâ€¢ ÎšÎ­Î½Ï„ÏÎ± Î±Ï€Î¿ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚\n\nÎ Î¡ÎŸÎ¥Î ÎŸÎ˜Î•Î£Î•Î™Î£ Î”ÎŸÎœÎ—Î£:\nâœ… ÎÏŒÎ¼Î¹Î¼Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ Î‘Î¦Îœ\nâœ… Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î®Ï‚ Î¼Îµ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Ï€ÏÎ¿ÏƒÏŒÎ½Ï„Î±\nâœ… Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ·Ï‚\n\nÎ•Î“ÎšÎ¡Î™Î£Î— Î”ÎŸÎœÎ—Î£: gsofianidis@mitropolitiko.edu.gr",
                "keywords": ["Î´Î¿Î¼Î­Ï‚", "Î´Î¿Î¼Î·", "Ï†Î¿ÏÎµÎ¯Ï‚", "Ï†Î¿ÏÎµÎ¹Ï‚", "ÏƒÏÎ»Î»Î¿Î³Î¿Ï‚", "ÏƒÏ…Î»Î»Î¿Î³Î¿Ï‚", "Î³Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î¿", "Î³Ï…Î¼Î½Î±ÏƒÏ„Î·ÏÎ¹Î¿", "ÎµÎ½ÏŒÏÎ³Î±Î½Î·", "ÎµÎ½Î¿ÏÎ³Î±Î½Î·", "Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿", "Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¹ÏÎ¿", "Î¼Ï€Î¬ÏƒÎºÎµÏ„", "Î¼Ï€Î±ÏƒÎºÎµÏ„", "ÎºÎ¿Î»Ï…Î¼Î²Î·Ï„Î®ÏÎ¹Î¿", "ÎºÎ¿Î»Ï…Î¼Î²Î·Ï„Î·ÏÎ¹Î¿", "Î±ÎºÎ±Î´Î·Î¼Î¯Î±", "Î±ÎºÎ±Î´Î·Î¼Î¹Î±", "fitness", "personal", "training", "Ï€Î¿Ï…", "Ï€Î¿Î¹ÎµÏ‚", "Ï€Î¿Î¹Î¿Ï…Ï‚", "Ï€Î¿Î¹Î±", "ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚", "ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î±ÏƒÎµÎ¹Ï‚"]
            },
            {
                "id": 30,
                "category": "ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ & Î‘Î¼Î¿Î¹Î²Î®",
                "question": "Î Î±Î¯ÏÎ½Ï‰ Î±Î¼Î¿Î¹Î²Î® Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·; Î¤Î¹ ÎºÏŒÏƒÏ„Î¿Ï‚ Î­Ï‡ÎµÎ¹ Î³Î¹Î± Ï„Î· Î´Î¿Î¼Î®;",
                "answer": "ÎŸÎ™ÎšÎŸÎÎŸÎœÎ™ÎšÎ‘ Î˜Î•ÎœÎ‘Î¤Î‘ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£:\n\nğŸ’° Î“Î™Î‘ Î¤ÎŸÎ¥Î£ Î¦ÎŸÎ™Î¤Î—Î¤Î•Î£:\nâŒ Î”Î•Î Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Î¼Î¿Î¹Î²Î®\nâ€¢ Î— Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î¼Î· Î±Î¼ÎµÎ¹Î²ÏŒÎ¼ÎµÎ½Î·\nâ€¢ Î‘Ï€Î¿Ï„ÎµÎ»ÎµÎ¯ Î¼Î­ÏÎ¿Ï‚ Ï„Ï‰Î½ ÏƒÏ€Î¿Ï…Î´ÏÎ½\nâ€¢ Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎµÏÎ³Î±ÏƒÎ¹Î±ÎºÎ® ÏƒÏ‡Î­ÏƒÎ·\n\nğŸ¢ Î“Î™Î‘ Î¤Î— Î”ÎŸÎœÎ—:\nâœ… Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿ Î® Î¼Î·Î´ÎµÎ½Î¹ÎºÏŒ ÎºÏŒÏƒÏ„Î¿Ï‚\nâ€¢ Î•Î½Î´ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÏŒ Ï„Î­Î»Î¿Ï‚\nâ€¢ Î¤Î¿ ÎºÎ¿Î»Î»Î­Î³Î¹Î¿ ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹ Î­Î¾Î¿Î´Î± ÏƒÏÎ¼Î²Î±ÏƒÎ·Ï‚\nâ€¢ Î‘ÏƒÏ†Î¬Î»Î¹ÏƒÎ· Ï„Î¹Î¼Î¿Î»Î¿Î³ÎµÎ¯Ï„Î±Î¹ ÏƒÏ„Î¿ ÎºÎ¿Î»Î»Î­Î³Î¹Î¿\nâ€¢ Î§Ï‰ÏÎ¯Ï‚ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Ï…Ï€Î¿Ï‡ÏÎ­Ï‰ÏƒÎ· Ï€ÏÎ¿Ï‚ Ï†Î¿Î¹Ï„Î·Ï„Î­Ï‚\n\nÎ Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£: gsofianidis@mitropolitiko.edu.gr",
                "keywords": ["Î±Î¼Î¿Î¹Î²Î®", "Î±Î¼Î¿Î¹Î²Î·", "Ï€Î»Î·ÏÏ‰Î¼Î®", "Ï€Î»Î·ÏÏ‰Î¼Î·", "Ï€Î»Î·ÏÏÎ¸Ï", "Ï€Î»Î·ÏÏ‰Î¸Ï", "Ï€Î»Î·ÏÏ‰Î¸Ï‰", "Ï€Î»Î·ÏÏ‰Î½Î¿Î¼Î±Î¹", "Ï€Î»Î·ÏÏÎ½Î¿Î¼Î±Î¹", "Î»ÎµÏ†Ï„Î¬", "Î»ÎµÏ†Ï„Î±", "Ï‡ÏÎ®Î¼Î±Ï„Î±", "Ï‡ÏÎ·Î¼Î±Ï„Î±", "ÎºÏŒÏƒÏ„Î¿Ï‚", "ÎºÎ¿ÏƒÏ„Î¿Ï‚", "Ï„Î­Î»Î¿Ï‚", "Ï„ÎµÎ»Î¿Ï‚", "Î´Î¿Î¼Î®", "Î´Î¿Î¼Î·", "Ï†Î¿Î¹Ï„Î·Ï„Î®Ï‚", "Ï†Î¿Î¹Ï„Î·Ï„Î·", "Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬", "Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ±", "Î¼Î¹ÏƒÎ¸ÏŒÏ‚", "Î¼Î¹ÏƒÎ¸Î¿Ï‚"]
            },
            {
                "id": 11,
                "category": "Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±",
                "question": "ÎœÎµ Ï€Î¿Î¹Î¿Î½ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Ï Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘Î£:\n\nğŸ‘¨â€ğŸ« ÎšÎ¥Î¡Î™Î‘ Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:\nÎ“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚, MSc, PhD(c)\nğŸ“§ gsofianidis@mitropolitiko.edu.gr\nğŸ·ï¸ Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚\n\nğŸ‘¨â€ğŸ’¼ Î•ÎÎ‘Î›Î›Î‘ÎšÎ¤Î™ÎšÎ— Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:\nÎ“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚, MSc, PhD\nğŸ“§ gbouchouras@mitropolitiko.edu.gr\nğŸ“ 2314 409000\nğŸ·ï¸ Programme Leader\n\nğŸ“‹ ÎšÎ‘Î¤Î—Î“ÎŸÎ¡Î™ÎŸÎ ÎŸÎ™Î—Î£Î— Î˜Î•ÎœÎ‘Î¤Î©Î:\nâ€¢ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î­Î³Î³ÏÎ±Ï†Î± âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚\nâ€¢ Î¤ÎµÏ‡Î½Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚\nâ€¢ Î˜Î­Î¼Î±Ï„Î± Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚\n\nâ° Î©Î¡Î‘Î¡Î™ÎŸ: Î”ÎµÏ…Ï„Î­ÏÎ±-Î Î±ÏÎ±ÏƒÎºÎµÏ…Î®, 9:00-17:00",
                "keywords": ["ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±", "ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¹Î±", "Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚", "Î£Î¿Ï†Î¹Î±Î½Î¹Î´Î·Ï‚", "ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚", "ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ±Ï‚", "email", "Ï„Î·Î»Î­Ï†Ï‰Î½Î¿", "Ï„Î·Î»ÎµÏ†Ï‰Î½Î¿", "Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚", "Ï…Ï€ÎµÏ…Î¸Ï…Î½Î¿Ï‚", "Î²Î¿Î®Î¸ÎµÎ¹Î±", "Î²Î¿Î·Î¸ÎµÎ¹Î±", "ÎºÎ±Î¸Î·Î³Î·Ï„Î®Ï‚", "ÎºÎ±Î¸Î·Î³Î·Ï„Î·Ï‚", "ÎºÎ±Î¸Î·Î³Î®Ï„ÏÎ¹Î±", "ÎºÎ±Î¸Î·Î³Î·Ï„ÏÎ¹Î±", "contact", "ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±", "ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¹Î±"]
            },
            {
                "id": 4,
                "category": "ÎÏÎµÏ‚ & Î§ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±",
                "question": "Î ÏŒÏƒÎµÏ‚ ÏÏÎµÏ‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ¬Î½Ï‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î§Î¡ÎŸÎÎ™ÎšÎ•Î£ Î‘Î Î‘Î™Î¤Î—Î£Î•Î™Î£:\n\nâ±ï¸ Î£Î¥ÎÎŸÎ›Î™ÎšÎ•Î£ Î©Î¡Î•Î£:\n240 ÏÏÎµÏ‚ (Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÏŒ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿)\n\nğŸ“… Î Î¡ÎŸÎ˜Î•Î£ÎœÎ™Î‘:\nÎœÎ­Ï‡ÏÎ¹ 30 ÎœÎ±ÎÎ¿Ï…\n\nğŸ“† ÎšÎ‘ÎÎŸÎÎ•Î£ Î©Î¡Î‘Î¡Î™ÎŸÎ¥:\nâ€¢ Î”ÎµÏ…Ï„Î­ÏÎ± Î­Ï‰Ï‚ Î£Î¬Î²Î²Î±Ï„Î¿\nâ€¢ ÎŒÎ§Î™ ÎšÏ…ÏÎ¹Î±ÎºÎ­Ï‚\nâ€¢ ÎœÎ­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±\nâ€¢ 5 Î·Î¼Î­ÏÎµÏ‚/ÎµÎ²Î´Î¿Î¼Î¬Î´Î±\n\nğŸ“Š Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘Î¤Î‘ Î Î¡ÎŸÎ“Î¡Î‘ÎœÎœÎ‘Î¤Î™Î£ÎœÎŸÎ¥:\nâ€¢ 6 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 40 ÏÏÎµÏ‚\nâ€¢ 8 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 30 ÏÏÎµÏ‚\nâ€¢ 10 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 24 ÏÏÎµÏ‚\n\nÎ£Î¥ÎœÎ¦Î©ÎÎ™Î‘: Î¤Î¿ Ï‰ÏÎ¬ÏÎ¹Î¿ Î¿ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î±Ï€ÏŒ Ï„Î· Î´Î¿Î¼Î® ÏƒÎµ ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Î±Î¶Î¯ ÏƒÎ±Ï‚\n\nÎ Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£: gsofianidis@mitropolitiko.edu.gr",
                "keywords": ["ÏÏÎµÏ‚", "Ï‰ÏÎµÏ‚", "240", "Ï€Î¿ÏƒÎµÏ‚", "Ï€ÏŒÏƒÎµÏ‚", "Ï€Î¿ÏƒÎ±", "Ï€Î¿ÏƒÎ¬", "ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬", "ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ±", "ÏŒÎ»ÎµÏ‚", "Î¿Î»ÎµÏ‚", "Ï„ÎµÎ»Î¹ÎºÎ¬", "Ï„ÎµÎ»Î¹ÎºÎ±", "Ï‡ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±", "Ï‡ÏÎ¿Î½Î¿Î´Î¹Î±Î³ÏÎ±Î¼Î¼Î±", "Î´Î¹Î¬ÏÎºÎµÎ¹Î±", "Î´Î¹Î±ÏÎºÎµÎ¹Î±", "Ï‡ÏÏŒÎ½Î¿Ï‚", "Ï‡ÏÎ¿Î½Î¿Ï‚", "30/5", "deadline", "Ï€ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±", "Ï€ÏÎ¿Î¸ÎµÏƒÎ¼Î¹Î±"]
            }
        ]

    def download_pdf_file(self, filename: str) -> str:
        """Memory-optimized PDF download and processing"""
        if not PDF_AVAILABLE:
            print(f"âš ï¸ No PDF library available, cannot process {filename}")
            return ""
        
        # Check cache first
        if filename in self.pdf_cache:
            print(f"ğŸ“‹ Using cached content for {filename}")
            return self.pdf_cache[filename]
        
        try:
            base_url = "https://raw.githubusercontent.com/GiorgosBouh/chatbot.placement/main/"
            url = base_url + filename
            
            print(f"ğŸ” Downloading {filename} from GitHub using {PDF_METHOD}...")
            
            response = requests.get(url, timeout=15)
            response.raise_for_status()
            
            text_content = []
            
            if PDF_METHOD == "PyPDF2":
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(response.content))
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text.strip():
                            # Memory optimization: limit content length
                            text_content.append(page_text.strip()[:2000])  # Limit per page
                    except Exception as e:
                        print(f"âš ï¸ Error extracting page {page_num}: {e}")
                
            elif PDF_METHOD == "PyMuPDF":
                pdf_document = fitz.open(stream=response.content, filetype="pdf")
                for page_num in range(min(pdf_document.page_count, 10)):  # Limit pages for memory
                    try:
                        page = pdf_document[page_num]
                        page_text = page.get_text()
                        if page_text.strip():
                            text_content.append(page_text.strip()[:2000])  # Limit per page
                    except Exception as e:
                        print(f"âš ï¸ Error extracting page {page_num}: {e}")
                pdf_document.close()
            
            full_text = "\n".join(text_content)
            
            # Memory optimization: Cache only essential content
            if len(full_text) > 5000:
                full_text = full_text[:5000] + "...\n[Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Ï€ÎµÏÎ¹Î¿ÏÎ¯ÏƒÏ„Î·ÎºÎµ Î³Î¹Î± Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î½Î®Î¼Î·Ï‚]"
            
            self.pdf_cache[filename] = full_text
            
            print(f"âœ… Successfully processed {filename} ({len(full_text)} characters)")
            return full_text
            
        except Exception as e:
            print(f"âŒ Failed to process {filename}: {e}")
            return ""

    def extract_concepts(self, question: str) -> Dict[str, float]:
        """Enhanced concept extraction with scoring"""
        question_lower = question.lower()
        detected_concepts = {}
        
        for concept, data in self.concept_patterns.items():
            matches = sum(1 for keyword in data['keywords'] if keyword in question_lower)
            if matches > 0:
                # Calculate concept strength
                strength = (matches / len(data['keywords'])) * data['weight']
                detected_concepts[concept] = strength
        
        return detected_concepts

    def enhanced_similarity_calculation(self, question: str, qa_entry: Dict) -> float:
        """Enhanced similarity calculation with concept weighting"""
        question_lower = question.lower()
        
        # Extract concepts
        question_concepts = self.extract_concepts(question)
        
        # Base keyword matching
        keyword_matches = sum(1 for keyword in qa_entry.get('keywords', []) 
                            if keyword.lower() in question_lower)
        keyword_score = keyword_matches / max(len(qa_entry.get('keywords', [])), 1) * 0.4
        
        # Title similarity
        title_words = qa_entry['question'].lower().split()
        question_words = [w for w in question_lower.split() if len(w) > 2]
        
        title_matches = sum(1 for word in title_words if word in question_lower and len(word) > 2)
        reverse_matches = sum(1 for word in question_words if word in qa_entry['question'].lower())
        title_score = (title_matches + reverse_matches) / max(len(title_words) + len(question_words), 1) * 0.3
        
        # Concept-category matching
        qa_category = qa_entry.get('category', '').lower()
        concept_score = 0
        
        for concept, strength in question_concepts.items():
            if concept == 'documents' and ('Î­Î³Î³ÏÎ±Ï†Î±' in qa_category or 'Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚' in qa_category):
                concept_score += strength * 0.3
            elif concept == 'facilities' and ('Î´Î¿Î¼Î­Ï‚' in qa_category or 'Ï†Î¿ÏÎµÎ¯Ï‚' in qa_category):
                concept_score += strength * 0.3
            elif concept == 'time' and ('ÏÏÎµÏ‚' in qa_category or 'Ï‡ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±' in qa_category):
                concept_score += strength * 0.3
            elif concept == 'money' and 'Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬' in qa_category:
                concept_score += strength * 0.3
            elif concept == 'contact' and 'ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±' in qa_category:
                concept_score += strength * 0.3
        
        total_score = keyword_score + title_score + concept_score
        return min(total_score, 1.0)

    def get_contextual_matches(self, question: str, max_matches: int = 3) -> List[Dict]:
        """Get contextually relevant Q&A matches"""
        if not self.qa_data:
            return []
        
        # Calculate similarities
        scored_matches = []
        for qa in self.qa_data:
            similarity = self.enhanced_similarity_calculation(question, qa)
            if similarity > 0.05:  # Threshold for relevance
                scored_matches.append((similarity, qa))
        
        # Sort and return top matches
        scored_matches.sort(key=lambda x: x[0], reverse=True)
        return [qa for score, qa in scored_matches[:max_matches]]

    def search_pdfs_intelligently(self, question: str, concepts: Dict[str, float]) -> str:
        """Intelligent PDF search with concept-based filtering"""
        if not PDF_AVAILABLE:
            return ""
        
        print("ğŸ“„ Searching PDFs with concept analysis...")
        
        question_lower = question.lower()
        question_words = [w for w in question_lower.split() if len(w) > 3]
        
        relevant_content = []
        
        for filename in self.pdf_files:
            content = self.download_pdf_file(filename)
            if content:
                content_lower = content.lower()
                
                # Calculate relevance score
                word_matches = sum(1 for word in question_words if word in content_lower)
                concept_matches = sum(strength for concept, strength in concepts.items() 
                                    if self._check_concept_in_pdf(concept, content_lower))
                
                relevance_score = word_matches * 0.4 + concept_matches * 0.6
                
                if relevance_score > 0.3:
                    # Extract relevant sections
                    sections = self._extract_relevant_sections(content, question_words, max_chars=800)
                    if sections:
                        relevant_content.append(f"[Î‘Ï€ÏŒ {filename}]\n{sections}")
                        print(f"âœ… Found relevant content in {filename} (score: {relevance_score:.2f})")
        
        return "\n\n".join(relevant_content) if relevant_content else ""

    def _check_concept_in_pdf(self, concept: str, text: str) -> bool:
        """Check if concept keywords exist in PDF text"""
        keywords = self.concept_patterns.get(concept, {}).get('keywords', [])
        return any(keyword in text for keyword in keywords)

    def _extract_relevant_sections(self, content: str, keywords: List[str], max_chars: int) -> str:
        """Extract most relevant sections from PDF content"""
        sentences = [s.strip() for s in content.split('.') if len(s.strip()) > 20]
        scored_sentences = []
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            matches = sum(1 for keyword in keywords if keyword in sentence_lower)
            if matches > 0:
                scored_sentences.append((matches, sentence))
        
        # Sort by relevance and combine
        scored_sentences.sort(key=lambda x: x[0], reverse=True)
        
        result = []
        char_count = 0
        for score, sentence in scored_sentences[:3]:  # Top 3 sentences
            if char_count + len(sentence) > max_chars:
                break
            result.append(sentence.strip())
            char_count += len(sentence)
        
        return '. '.join(result) + ('.' if result else '')

    def get_smart_ai_response(self, user_message: str) -> Tuple[str, bool]:
        """Enhanced AI response with intelligent context building"""
        if not self.groq_client:
            return "", False
        
        try:
            # Extract concepts
            concepts = self.extract_concepts(user_message)
            print(f"ğŸ§  Detected concepts: {list(concepts.keys())}")
            
            # Get relevant Q&A matches
            qa_matches = self.get_contextual_matches(user_message)
            
            # Get relevant PDF content
            pdf_content = self.search_pdfs_intelligently(user_message, concepts)
            
            # Build context
            context_parts = []
            
            if pdf_content:
                context_parts.append(f"Î•Î Î™Î£Î—ÎœÎ‘ Î•Î“Î“Î¡Î‘Î¦Î‘:\n{pdf_content}")
            
            if qa_matches:
                qa_context = "\n\n".join([
                    f"Î•Î¡Î©Î¤Î—Î£Î—: {qa['question']}\nÎ‘Î Î‘ÎÎ¤Î—Î£Î—: {qa['answer']}"
                    for qa in qa_matches
                ])
                context_parts.append(f"Î’Î‘Î£Î— Î“ÎÎ©Î£Î—Î£:\n{qa_context}")
            
            # Enhanced prompt
            if context_parts:
                combined_context = "\n\n" + ("="*40 + "\n\n").join(context_parts)
                
                full_prompt = f"""Î”Î™Î‘Î˜Î•Î£Î™ÎœÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£:
{combined_context}

Î•Î¡Î©Î¤Î—Î£Î— Î¦ÎŸÎ™Î¤Î—Î¤Î—: {user_message}

Î•ÎÎ¤ÎŸÎ Î™Î£ÎœÎ•ÎÎ•Î£ Î•ÎÎÎŸÎ™Î•Î£: {', '.join(concepts.keys()) if concepts else 'Î“ÎµÎ½Î¹ÎºÎ® ÎµÏÏÏ„Î·ÏƒÎ·'}

ÎŸÎ”Î—Î“Î™Î•Î£ Î•ÎÎ¥Î ÎÎ—Î£ Î‘ÎÎ‘Î›Î¥Î£Î—Î£:
1. Î‘Î½Î±Î»ÏÏƒÎµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Î³Î¹Î± Ï„Î¿ Ï„Î¹ Î¶Î·Ï„Î¬ÎµÎ¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Î¿ Ï†Î¿Î¹Ï„Î·Ï„Î®Ï‚
2. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Î•Î Î™Î£Î—ÎœÎ‘ Î•Î“Î“Î¡Î‘Î¦Î‘ Ï‰Ï‚ ÎºÏÏÎ¹Î± Ï€Î·Î³Î®
3. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Î¼Îµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î· Î’Î‘Î£Î— Î“ÎÎ©Î£Î—Î£
4. Î£Ï…Î½Î´ÏÎ±ÏƒÎµ Î¼Îµ Î»Î¿Î³Î¹ÎºÏŒ ÏƒÏ…Î¼Ï€ÎµÏÎ±ÏƒÎ¼ÏŒ ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
5. Î”ÏÏƒÎµ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚, Î´Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ Î¿Î´Î·Î³Î¯ÎµÏ‚
6. Î‘Î½Î±Ï†Î­ÏÎ¿Ï… Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎµÏ€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î´Î¿Î¼Î·Î¼Î­Î½Î¿ Ï„ÏÏŒÏ€Î¿ ÎºÎ±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏŒÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬."""
            else:
                # Fallback prompt with enhanced reasoning
                full_prompt = f"""Î•Î¡Î©Î¤Î—Î£Î— Î¦ÎŸÎ™Î¤Î—Î¤Î—: {user_message}

Î Î›Î‘Î™Î£Î™ÎŸ: Î¦Î¿Î¹Ï„Î·Ï„Î®Ï‚ Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚, ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚

Î•ÎÎ¤ÎŸÎ Î™Î£ÎœÎ•ÎÎ•Î£ Î•ÎÎÎŸÎ™Î•Î£: {', '.join(concepts.keys()) if concepts else 'Î“ÎµÎ½Î¹ÎºÎ® ÎµÏÏÏ„Î·ÏƒÎ·'}

Î’Î‘Î£Î™ÎšÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£:
- Î‘Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ 240 ÏÏÎµÏ‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ Î¼Î­Ï‡ÏÎ¹ 30 ÎœÎ±ÎÎ¿Ï…
- Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿, Î¼Î­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±
- Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚ (gsofianidis@mitropolitiko.edu.gr)
- Î Î±ÏÎ¬Î´Î¿ÏƒÎ· ÏƒÏ…Î¼Î²Î¬ÏƒÎµÏ‰Î½ ÏƒÏ„Î¿ Moodle Î¼Î­Ï‡ÏÎ¹ 15 ÎŸÎºÏ„Ï‰Î²ÏÎ¯Î¿Ï…

ÎŸÎ”Î—Î“Î™Î•Î£:
1. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î³ÎµÎ½Î¹ÎºÎ® Î³Î½ÏÏƒÎ· Î³Î¹Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ· ÏƒÏ„Î·Î½ Î•Î»Î»Î¬Î´Î±
2. Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎµ Î¼Îµ Ï„Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ Ï„Î¿Ï… ÎºÎ¿Î»Î»ÎµÎ³Î¯Î¿Ï…
3. Î”ÏÏƒÎµ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î­Ï‚ Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î¹Ï‚ ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼Î­Î½ÎµÏ‚ Î­Î½Î½Î¿Î¹ÎµÏ‚
4. Î ÏÏŒÏ„ÎµÎ¹Î½Îµ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± Î¼Îµ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿ Î³Î¹Î± ÎµÏ€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ·

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏŒÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬."""

            # Call Groq API
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": full_prompt}
                ],
                model="llama-3.1-8b-instant",
                temperature=0.2,  # Lower for consistency
                max_tokens=1000,
                top_p=0.9,
                stream=False
            )

            response = chat_completion.choices[0].message.content
            
            # Validate Greek characters
            if response and any(ord(char) > 1500 and ord(char) not in range(0x0370, 0x03FF) for char in response):
                print("âš ï¸ Detected non-Greek characters in response")
                return "", False
            
            print("âœ… Smart AI response generated successfully")
            return response, True
            
        except Exception as e:
            print(f"âŒ Smart AI Error: {e}")
            return "", False

    def get_concept_based_fallback(self, question: str) -> str:
        """Enhanced concept-based smart fallback"""
        concepts = self.extract_concepts(question)
        question_lower = question.lower()
        
        # Prioritize concepts by strength
        top_concept = max(concepts.items(), key=lambda x: x[1])[0] if concepts else None
        
        if top_concept == 'facilities' or any(keyword in question_lower for keyword in ['ÏƒÏÎ»Î»Î¿Î³Î¿', 'Î³Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î¿', 'Î´Î¿Î¼Î®', 'Ï†Î¿ÏÎ­Î±']):
            return """Î•Î“ÎšÎ•ÎšÎ¡Î™ÎœÎ•ÎÎ•Î£ Î”ÎŸÎœÎ•Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£ Î‘Î£ÎšÎ—Î£Î—Î£:

ğŸƒâ€â™‚ï¸ Î‘Î˜Î›Î—Î¤Î™ÎšÎ•Î£ Î•Î“ÎšÎ‘Î¤Î‘Î£Î¤Î‘Î£Î•Î™Î£:
â€¢ Î‘Î¸Î»Î·Ï„Î¹ÎºÎ¿ÏÏ‚ ÏƒÏ…Î»Î»ÏŒÎ³Î¿Ï…Ï‚ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î±Î¸Î»Î·Î¼Î¬Ï„Ï‰Î½
â€¢ Î“Ï…Î¼Î½Î±ÏƒÏ„Î®ÏÎ¹Î± ÎºÎ±Î¹ fitness centers
â€¢ ÎšÎ¿Î»Ï…Î¼Î²Î·Ï„Î®ÏÎ¹Î±
â€¢ Î‘ÎºÎ±Î´Î·Î¼Î¯ÎµÏ‚ Î±Î¸Î»Î·Ï„Î¹ÏƒÎ¼Î¿Ï
â€¢ Personal training studios
â€¢ ÎšÎ­Î½Ï„ÏÎ± Î±Ï€Î¿ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚

ğŸ›ï¸ Î”Î—ÎœÎŸÎ£Î™ÎŸÎ™ Î¦ÎŸÎ¡Î•Î™Î£:
â€¢ Î”Î·Î¼ÏŒÏƒÎ¹Î¿Ï…Ï‚ Î±Î¸Î»Î·Ï„Î¹ÎºÎ¿ÏÏ‚ Î¿ÏÎ³Î±Î½Î¹ÏƒÎ¼Î¿ÏÏ‚
â€¢ Î£Ï‡Î¿Î»ÎµÎ¯Î± Î¼Îµ Ï„Î¼Î®Î¼Î± Ï†Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î±Î³Ï‰Î³Î®Ï‚

âœ… Î Î¡ÎŸÎ«Î ÎŸÎ˜Î•Î£Î•Î™Î£:
â€¢ ÎÏŒÎ¼Î¹Î¼Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ Î‘Î¦Îœ
â€¢ Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î®Ï‚ Î¼Îµ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Ï€ÏÎ¿ÏƒÏŒÎ½Ï„Î±
â€¢ Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ·Ï‚

Î•Î“ÎšÎ¡Î™Î£Î— Î”ÎŸÎœÎ—Î£: gsofianidis@mitropolitiko.edu.gr"""

        elif top_concept == 'documents' or any(keyword in question_lower for keyword in ['Î­Î³Î³ÏÎ±Ï†Î±', 'Ï‡Î±ÏÏ„Î¹Î¬', 'Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±']):
            return """Î‘Î Î‘Î™Î¤ÎŸÎ¥ÎœÎ•ÎÎ‘ Î•Î“Î“Î¡Î‘Î¦Î‘ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£:

ğŸ“‹ Î“Î™Î‘ Î¤ÎŸÎ Î¦ÎŸÎ™Î¤Î—Î¤Î—:
â€¢ Î‘Î¯Ï„Î·ÏƒÎ· Ï€ÏÎ±Î³Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚
â€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿Î¹Ï„Î·Ï„Î® (ÏƒÏ…Î¼Ï€Î»Î·ÏÏ‰Î¼Î­Î½Î· Ï†ÏŒÏÎ¼Î±)
â€¢ Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Î±Ï€ÏŒ gov.gr
â€¢ Î¥Ï€ÎµÏÎ¸Ï…Î½Î· Î´Î®Î»Ï‰ÏƒÎ· (Î¼Î· Î»Î®ÏˆÎ· ÎµÏ€Î¹Î´ÏŒÎ¼Î±Ï„Î¿Ï‚)

ğŸ¢ Î“Î™Î‘ Î¤Î— Î”ÎŸÎœÎ—:
â€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿ÏÎ­Î± (Î‘Î¦Îœ, Î´Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·, ÎµÎºÏ€ÏÏŒÏƒÏ‰Ï€Î¿Ï‚)
â€¢ Î—Î¼Î­ÏÎµÏ‚ ÎºÎ±Î¹ ÏÏÎµÏ‚ Î´ÎµÎºÏ„ÏŒÏ„Î·Ï„Î±Ï‚

âš ï¸ Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ:
ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± - Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï‡ÏÏŒÎ½Î¿!

Î Î—Î“Î—: Moodle SE5117
Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘: gsofianidis@mitropolitiko.edu.gr"""

        elif top_concept == 'time' or any(keyword in question_lower for keyword in ['ÏÏÎµÏ‚', 'Ï‡ÏÏŒÎ½Î¿Ï‚', 'Ï€ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±']):
            return """Î§Î¡ÎŸÎÎ™ÎšÎ•Î£ Î‘Î Î‘Î™Î¤Î—Î£Î•Î™Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£:

â±ï¸ Î£Î¥ÎÎŸÎ›Î™ÎšÎ•Î£ Î©Î¡Î•Î£: 240 ÏÏÎµÏ‚ (Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÏŒ)
ğŸ“… Î Î¡ÎŸÎ˜Î•Î£ÎœÎ™Î‘: 30 ÎœÎ±ÎÎ¿Ï…

ğŸ“† ÎšÎ‘ÎÎŸÎÎ•Î£ Î©Î¡Î‘Î¡Î™ÎŸÎ¥:
â€¢ Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿ (ÏŒÏ‡Î¹ ÎšÏ…ÏÎ¹Î±ÎºÎ­Ï‚)
â€¢ ÎœÎ­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±
â€¢ 5 Î·Î¼Î­ÏÎµÏ‚/ÎµÎ²Î´Î¿Î¼Î¬Î´Î±

ğŸ“Š Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘Î¤Î‘ Î Î¡ÎŸÎ“Î¡Î‘ÎœÎœÎ‘Î¤Î™Î£ÎœÎŸÎ¥:
â€¢ 6 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 40 ÏÏÎµÏ‚
â€¢ 8 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 30 ÏÏÎµÏ‚
â€¢ 10 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ Ã— 24 ÏÏÎµÏ‚

Î Î¡ÎŸÎ“Î¡Î‘ÎœÎœÎ‘Î¤Î™Î£ÎœÎŸÎ£: gsofianidis@mitropolitiko.edu.gr"""

        elif top_concept == 'contact' or any(keyword in question_lower for keyword in ['ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±', 'Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚']):
            return """Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘Î£:

ğŸ‘¨â€ğŸ« ÎšÎ¥Î¡Î™Î‘ Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:
Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚, MSc, PhD(c)
ğŸ“§ gsofianidis@mitropolitiko.edu.gr
ğŸ·ï¸ Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚

ğŸ‘¨â€ğŸ’¼ Î•ÎÎ‘Î›Î›Î‘ÎšÎ¤Î™ÎšÎ— Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:
Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚, MSc, PhD
ğŸ“§ gbouchouras@mitropolitiko.edu.gr
ğŸ“ 2314 409000
ğŸ·ï¸ Programme Leader

ğŸ“‹ ÎšÎ‘Î¤Î—Î“ÎŸÎ¡Î™ÎŸÎ ÎŸÎ™Î—Î£Î—:
â€¢ Î˜Î­Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚
â€¢ Î¤ÎµÏ‡Î½Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚"""

        else:
            return f"""Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.

Î Î¡ÎŸÎ¤Î•Î™ÎÎŸÎœÎ•ÎÎ•Î£ Î•ÎÎ•Î¡Î“Î•Î™Î•Î£:
â€¢ Î”Î¹Î±Ï„Ï…Ï€ÏÏƒÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï€Î¹Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î±
â€¢ Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î±Ï€ÏŒ Ï„Î¹Ï‚ ÏƒÏ…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Î¼ÎµÎ½Î¿Ï
â€¢ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Î¼Îµ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿

Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:
ğŸ“§ gsofianidis@mitropolitiko.edu.gr
ğŸ“ 2314 409000

Î“Î¹Î± Î¬Î¼ÎµÏƒÎ· Î²Î¿Î®Î¸ÎµÎ¹Î±, Ï€ÎµÏÎ¹Î³ÏÎ¬ÏˆÏ„Îµ Ï„Î· ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î±Ï€Î¿ÏÎ¯Î± ÏƒÎ±Ï‚."""

    def get_response(self, question: str) -> str:
        """Main response method - optimized for memory efficiency"""
        if not self.qa_data:
            return "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î½ÏÏƒÎ·Ï‚."
        
        print(f"\nğŸ¤– Processing question: '{question}'")
        
        # Step 1: Check for high-similarity direct matches
        print("ğŸ“‹ Step 1: Checking for direct matches...")
        best_match = max(self.qa_data, key=lambda x: self.enhanced_similarity_calculation(question, x))
        similarity = self.enhanced_similarity_calculation(question, best_match)
        
        if similarity > 0.4:  # High confidence threshold
            print(f"âœ… High similarity match found (score: {similarity:.3f})")
            return best_match['answer']
        
        # Step 2: Enhanced AI processing with context
        print("ğŸ§  Step 2: Enhanced AI processing...")
        if self.groq_client:
            response, success = self.get_smart_ai_response(question)
            if success and response.strip():
                print("âœ… Smart AI response successful")
                return response
            else:
                print("âš ï¸ AI processing failed")
        else:
            print("âš ï¸ AI not available")
        
        # Step 3: Concept-based intelligent fallback
        print("ğŸ“‹ Step 3: Using intelligent fallback...")
        if similarity > 0.15:  # Medium confidence
            print(f"ğŸŸ¡ Medium similarity fallback (score: {similarity:.3f})")
            return best_match['answer']
        else:
            print("ğŸ”„ Using concept-based smart fallback")
            return self.get_concept_based_fallback(question)

def main():
    """Main Streamlit application - Optimized for Community Cloud"""
    
    # Enhanced Responsive CSS Styling
    st.markdown("""
    <style>
    /* Base responsive styles */
    .main-header {
        background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 2rem;
        flex-wrap: wrap;
    }
    
    .header-content {
        flex: 1;
        min-width: 300px;
    }
    
    .header-logo {
        max-height: 80px;
        max-width: 120px;
        object-fit: contain;
        flex-shrink: 0;
    }
    
    .user-message {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border: 1px solid #dee2e6;
        border-left: 4px solid #007bff;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        color: #333;
        word-wrap: break-word;
        overflow-wrap: break-word;
    }
    
    .ai-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-left: 4px solid #4caf50;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        word-wrap: break-word;
        overflow-wrap: break-word;
    }
    
    .ai-message a {
        color: #ffeb3b !important;
        text-decoration: underline !important;
        font-weight: bold !important;
    }
    
    .ai-message a:hover {
        color: #fff9c4 !important;
        text-decoration: underline !important;
    }
    
    .info-card {
        background: white;
        border: 1px solid #e8f4f8;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
        min-height: 120px;
        display: flex;
        flex-direction: column;
        justify-content: center;
    }
    
    .info-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 16px rgba(0,0,0,0.12);
    }
    
    .api-status {
        position: fixed;
        top: 20px;
        right: 20px;
        background: #28a745;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        z-index: 1000;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .optimized-status {
        background: linear-gradient(45deg, #4ecdc4, #44a08d);
        animation: pulse 2s ease-in-out infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.8; }
    }
    
    .chat-container {
        background: white;
        border-radius: 10px;
        padding: 1rem;
        margin-top: 2rem;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        border: 1px solid #e8f4f8;
    }
    
    .stTextInput > div > div > input {
        border-radius: 20px;
        border: 2px solid #e8f4f8;
        padding: 0.8rem 1.2rem;
        font-size: 16px;
    }
    
    .stButton > button {
        background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%);
        color: white;
        border: none;
        border-radius: 20px;
        padding: 0.6rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        width: 100%;
        min-height: 44px;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(31, 78, 121, 0.3);
    }
    
    /* Responsive breakpoints */
    @media screen and (max-width: 768px) {
        .main-header {
            padding: 1rem;
            gap: 1rem;
            flex-direction: column;
            text-align: center;
        }
        
        .header-content h1 {
            font-size: 1.5rem !important;
            margin-bottom: 0.5rem;
        }
        
        .header-content h3 {
            font-size: 1rem !important;
            margin-bottom: 0.5rem;
        }
        
        .header-content p {
            font-size: 0.9rem !important;
        }
        
        .header-logo {
            max-height: 60px;
            max-width: 100px;
        }
        
        .info-card {
            margin: 0.25rem;
            padding: 1rem;
            min-height: auto;
        }
        
        .info-card h4 {
            font-size: 1rem !important;
        }
        
        .info-card p {
            font-size: 1rem !important;
        }
        
        .info-card small {
            font-size: 0.8rem !important;
        }
        
        .chat-container {
            padding: 0.5rem;
            margin-left: -1rem;
            margin-right: -1rem;
            border-radius: 0;
        }
        
        .user-message, .ai-message {
            padding: 0.75rem;
            font-size: 0.9rem;
        }
        
        .api-status {
            position: relative;
            top: auto;
            right: auto;
            margin: 1rem 0;
            display: inline-block;
            font-size: 0.8rem;
        }
    }
    
    @media screen and (max-width: 480px) {
        .main-header {
            padding: 0.75rem;
        }
        
        .header-content h1 {
            font-size: 1.25rem !important;
        }
        
        .header-content h3 {
            font-size: 0.9rem !important;
        }
        
        .info-card {
            padding: 0.75rem;
        }
        
        .info-card h4 {
            font-size: 0.9rem !important;
            margin-bottom: 0.25rem !important;
        }
        
        .info-card p {
            font-size: 0.9rem !important;
            margin: 0.25rem 0 !important;
        }
        
        .user-message, .ai-message {
            padding: 0.5rem;
            font-size: 0.85rem;
            margin: 0.5rem 0;
        }
        
        .stButton > button {
            padding: 0.5rem 1rem;
            font-size: 0.9rem;
        }
    }
    
    /* Hide scrollbars but keep functionality */
    .stApp {
        overflow-x: hidden;
    }
    
    /* Ensure content doesn't break on very small screens */
    * {
        max-width: 100%;
        box-sizing: border-box;
    }
    
    /* Better text scaling */
    html {
        -webkit-text-size-adjust: 100%;
        -ms-text-size-adjust: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

    # Header with Logo
    logo_url = "https://raw.githubusercontent.com/GiorgosBouh/chatbot.placement/main/MK_LOGO_SEO_1200x630.png"
    
    st.markdown(f"""
    <div class="main-header">
        <img src="{logo_url}" alt="ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿" class="header-logo">
        <div class="header-content">
            <h1>Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ·</h1>
            <h3>ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ - Î¤Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚</h3>
            <p><em>ğŸ§  Memory-Optimized Smart Assistant Î³Î¹Î± Community Cloud</em></p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Initialize session state
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    if 'chatbot' not in st.session_state:
        # Get Groq API key
        groq_api_key = None
        try:
            groq_api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
        except:
            pass
        
        st.session_state.chatbot = OptimizedInternshipChatbot(groq_api_key)
    else:
        # Refresh data if needed
        current_data_count = len(st.session_state.chatbot.qa_data)
        st.session_state.chatbot.qa_data = st.session_state.chatbot.load_qa_data()
        new_data_count = len(st.session_state.chatbot.qa_data)
        
        if new_data_count != current_data_count:
            st.toast(f"ğŸ“Š Data updated: {new_data_count} entries")

    # Quick info cards
    st.markdown("### ğŸ“Š Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚")
    
    quick_col1, quick_col2, quick_col3 = st.columns([1, 1, 1])
    
    with quick_col1:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“… Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ ÎÏÎµÏ‚</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #28a745; margin: 0;">240 ÏÏÎµÏ‚</p>
            <small style="color: #6c757d;">Î ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±: 30 ÎœÎ±ÏŠÎ¿Ï…</small>
        </div>
        """, unsafe_allow_html=True)

    with quick_col2:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“‹ Î Î±ÏÎ¬Î´Î¿ÏƒÎ· Î£Ï…Î¼Î²Î¬ÏƒÎµÏ‰Î½</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #ffc107; margin: 0;">Moodle Platform</p>
            <small style="color: #6c757d;">Î ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±: 15 ÎŸÎºÏ„Ï‰Î²ÏÎ¯Î¿Ï…</small>
        </div>
        """, unsafe_allow_html=True)

    with quick_col3:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">â° Î•Ï€Î¹Ï„ÏÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ Î©ÏÎ¬ÏÎ¹Î¿</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #17a2b8; margin: 0;">Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿</p>
            <small style="color: #6c757d;">ÎœÎ­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚ Î±Î½Î¬ Î·Î¼Î­ÏÎ±</small>
        </div>
        """, unsafe_allow_html=True)

    # Optimized Status Indicator
    if st.session_state.chatbot.groq_client:
        st.markdown('<div class="api-status optimized-status">ğŸ§  Smart Mode (Optimized)</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="api-status" style="background: #ffc107; color: #000;">ğŸ“‹ Concept Mode</div>', unsafe_allow_html=True)

    # Enhanced status information
    if st.session_state.chatbot.groq_client:
        status_text = "Smart Matching â†’ Enhanced AI â†’ Concept Fallback"
    else:
        status_text = "Smart Matching â†’ Concept-Based Responses"
    
    st.markdown(f"""
    <div style="background: #f8f9fa; border: 1px solid #dee2e6; border-radius: 4px; padding: 0.6rem; margin-bottom: 1.5rem; text-align: center; font-size: 0.9rem;">
        <strong>ğŸ§  Memory-Optimized Smart Assistant:</strong> Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Î³Î¹Î± Streamlit Community Cloud<br>
        <small>ğŸ”„ Logic: {status_text}</small>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.markdown("## ğŸ—£ï¸ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±")
        
        st.markdown("""
        **Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚**  
        **Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚**  
        **ğŸ“ 2314409000**
        **ğŸ“§ gsofianidis@mitropolitiko.edu.gr**
        
        **Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚/Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·/Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·**  
        **Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚**  
        ğŸ“§ gbouchouras@mitropolitiko.edu.gr

        âš ï¸ ÎšÎ±Î½Î­Î½Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î® ÎºÎ±Ï„Î±Ï„Î¯Î¸ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ Ï€Î±ÏÎ¿ÏÏƒÎ± ÎµÏ†Î±ÏÎ¼Î¿Î³Î®
        """)

        st.markdown("---")

        # Frequent questions
        st.markdown("## ğŸ”„ Î£Ï…Ï‡Î½Î­Ï‚ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚")
        
        categories = {}
        for qa in st.session_state.chatbot.qa_data:
            cat = qa.get('category', 'Î†Î»Î»Î±')
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(qa)

        for category, questions in categories.items():
            with st.expander(f"ğŸ“‚ {category}"):
                for qa in questions:
                    if st.button(qa['question'], key=f"faq_{qa['id']}", use_container_width=True):
                        st.session_state.messages.append({"role": "user", "content": qa['question']})
                        st.session_state.messages.append({"role": "assistant", "content": qa['answer']})
                        st.rerun()

        st.markdown("---")

        # System Status
        if st.session_state.chatbot.groq_client:
            st.success("ğŸ§  Smart AI Mode Active")
            st.info("Enhanced concept analysis + AI reasoning")
        else:
            st.warning("ğŸ“‹ Concept-Based Mode")
            if GROQ_AVAILABLE:
                st.info("For AI enhancement, add Groq API key")
            else:
                st.error("Groq library not available")

        # Memory optimization notice
        st.info("âš¡ Optimized for Community Cloud memory limits")

        st.markdown("---")

        if st.button("ğŸ—‘ï¸ ÎÎ­Î± Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

        # Technical Information
        with st.expander("ğŸ”§ System Details"):
            st.markdown("**Technical Support:**")
            st.markdown("ğŸ“§ gbouchouras@mitropolitiko.edu.gr")
            
            st.write("**Optimized System Status:**")
            st.write("â€¢ Memory Mode: Community Cloud Optimized âœ…")
            st.write("â€¢ Enhanced Concept Analysis: Active âœ…")
            st.write("â€¢ Smart Similarity Matching: Active âœ…")
            st.write("â€¢ Groq Available:", GROQ_AVAILABLE)
            st.write("â€¢ Groq Client:", st.session_state.chatbot.groq_client is not None)
            st.write("â€¢ PDF Available:", PDF_AVAILABLE)
            st.write("â€¢ RAG Libraries:", RAG_AVAILABLE, "(Not used for memory optimization)")
            
            st.write("**Data Sources:**")
            st.write("â€¢ QA Data Count:", len(st.session_state.chatbot.qa_data))
            st.write("â€¢ PDF Files:", len(st.session_state.chatbot.pdf_files))
            cached_pdfs = len(st.session_state.chatbot.pdf_cache)
            st.write(f"â€¢ Cached PDFs: {cached_pdfs}/{len(st.session_state.chatbot.pdf_files)}")
            
            # Concept analysis test
            st.subheader("ğŸ§  Concept Analysis Test")
            test_question = st.text_input("Test concept detection:", placeholder="Î¤Î¹ Î­Î³Î³ÏÎ±Ï†Î± Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹;")
            if test_question:
                concepts = st.session_state.chatbot.extract_concepts(test_question)
                if concepts:
                    st.write("**Detected Concepts:**")
                    for concept, strength in concepts.items():
                        st.write(f"â€¢ {concept}: {strength:.3f}")
                else:
                    st.write("No specific concepts detected")
                
                # Test similarity
                if st.session_state.chatbot.qa_data:
                    best_match = max(st.session_state.chatbot.qa_data, 
                                   key=lambda x: st.session_state.chatbot.enhanced_similarity_calculation(test_question, x))
                    similarity = st.session_state.chatbot.enhanced_similarity_calculation(test_question, best_match)
                    st.write(f"**Best match similarity:** {similarity:.3f}")
                    st.write(f"**Would use:** {'Direct match' if similarity > 0.4 else 'AI enhancement' if similarity > 0.15 else 'Concept fallback'}")

    # Chat interface
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    st.markdown("### ğŸ’¬ ÎšÎ¬Î½Ï„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚")

    # Display chat messages
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f'<div class="user-message"><strong>Î•ÏƒÎµÎ¯Ï‚:</strong> {message["content"]}</div>', unsafe_allow_html=True)
        else:
            content = message["content"].replace('\n', '<br>')
            assistant_name = "ğŸ§  Smart Assistant" if st.session_state.chatbot.groq_client else "ğŸ“‹ Concept Assistant"
            st.markdown(f'<div class="ai-message"><strong>{assistant_name}:</strong><br><br>{content}</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

    # Chat input
    user_input = st.chat_input("Î“ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚ ÎµÎ´Ï...")
    
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        spinner_text = "Î‘Î½Î±Î»ÏÏ‰ Î¼Îµ Î­Î¾Ï…Ï€Î½Î¿Ï…Ï‚ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚..." if st.session_state.chatbot.groq_client else "Î‘Î½Î±Î»ÏÏ‰ Î¼Îµ Î­Î½Î½Î¿Î¹ÎµÏ‚..."
        
        with st.spinner(spinner_text):
            try:
                response = st.session_state.chatbot.get_response(user_input)
            except Exception as e:
                response = f"Î£Ï…Î³Î³Î½ÏÎ¼Î·, Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î±: {str(e)}"
                st.error(f"Error: {e}")
        
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.rerun()

    # Footer
    footer_text = "Memory-Optimized Smart Assistant" if st.session_state.chatbot.groq_client else "Enhanced Concept-Based Assistant"
    st.markdown(f"""
    <div style="text-align: center; color: #6c757d; padding: 1rem; font-size: 0.9rem;">
        <small>
            ğŸ“ <strong>ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚</strong> | 
            Î¤Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚<br>
            <em>{footer_text}</em><br>
            <em>âš¡ Optimized for Streamlit Community Cloud</em>
        </small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()    main()