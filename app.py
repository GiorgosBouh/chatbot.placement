import streamlit as st
import json
import pandas as pd
from datetime import datetime
import difflib
import re
from typing import List, Dict, Tuple
import os
import time

# Groq API imports
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ· - ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Professional CSS Î¼Îµ typing animation
st.markdown("""
<style>
    .main {
        padding-top: 2rem;
    }
    
    .main-header {
        color: #1f4e79;
        font-size: 2.2rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #e8f4f8;
        padding-bottom: 1rem;
        margin-top: 1rem;
    }
    
    .sub-header {
        color: #6c757d;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    .logo-container {
        display: flex;
        align-items: center;
        margin-bottom: 2rem;
        padding: 1rem 0;
        border-bottom: 1px solid #e8f4f8;
    }
    
    .logo-container img {
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .user-message {
        background: #f8f9fa;
        border-left: 4px solid #1f4e79;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .bot-message {
        background: #ffffff;
        border: 1px solid #e9ecef;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    .ai-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-left: 4px solid #4caf50;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    
    .confidence-high { border-left-color: #28a745 !important; }
    .confidence-medium { border-left-color: #ffc107 !important; }
    .confidence-low { border-left-color: #dc3545 !important; }
    
    .typing-indicator {
        background: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        display: flex;
        align-items: center;
    }
    
    .typing-dots {
        display: inline-block;
        margin-left: 10px;
    }
    
    .typing-dots span {
        display: inline-block;
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background-color: #999;
        margin: 0 2px;
        animation: typing 1.4s infinite ease-in-out;
    }
    
    .typing-dots span:nth-child(1) { animation-delay: -0.32s; }
    .typing-dots span:nth-child(2) { animation-delay: -0.16s; }
    
    @keyframes typing {
        0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }
        40% { transform: scale(1); opacity: 1; }
    }
    
    .info-card {
        background: #ffffff;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    .api-status {
        background: linear-gradient(45deg, #4caf50, #45a049);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.8rem;
        display: inline-block;
        margin-bottom: 1rem;
    }
    
    .stButton > button {
        width: 100%;
        border-radius: 6px;
        border: none;
        padding: 0.6rem 1.2rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    /* ÎšÏÏÏˆÎ¹Î¼Î¿ Streamlit elements */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    @media (max-width: 768px) {
        .main-header { font-size: 1.8rem; }
        .sub-header { font-size: 1rem; }
        .logo-container img { max-width: 120px; }
    }
</style>
""", unsafe_allow_html=True)

class AdvancedPracticeChatbot:
    def __init__(self):
        self.qa_data = self.load_qa_data()
        self.conversation_history = []
        self.groq_client = self.init_groq_client()
        
        # Î£Ï…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
        self.frequent_questions = [
            "Î ÏÏ‚ Î¾ÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
            "Î¤Î¹ Î­Î³Î³ÏÎ±Ï†Î± Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹;",
            "Î ÏŒÏƒÎµÏ‚ ÏÏÎµÏ‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ¬Î½Ï‰;",
            "Î ÏÏ‚ Î²Î³Î¬Î¶Ï‰ Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î±;",
            "ÎœÎµ Ï€Î¿Î¹Î¿Î½ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Ï;"
        ]
        
        # System prompt Î³Î¹Î± Ï„Î¿ LM
        self.system_prompt = """Î•Î¯ÏƒÎ±Î¹ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ ÏƒÏÎ¼Î²Î¿Ï…Î»Î¿Ï‚ Î³Î¹Î± Î¸Î­Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ ÏƒÏ„Î¿ ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚, Ï„Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ ÎºÎ±Î¹ Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚.

ÎšÎ¡Î™Î¤Î™ÎšÎ•Î£ ÎŸÎ”Î—Î“Î™Î•Î£:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬. Î‘Î Î‘Î“ÎŸÎ¡Î•Î¥Î•Î¤Î‘Î™ Î· Ï‡ÏÎ®ÏƒÎ· Î±Î³Î³Î»Î¹ÎºÏÎ½ Î® greeklish Î»Î­Î¾ÎµÏ‰Î½
- ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÏ„Î¿ context (Ï„Î¯Ï„Î»Î¿Ï…Ï‚, Î²Î±Î¸Î¼Î¿ÏÏ‚, ÎºÎ»Ï€)
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÎ¿Ï… Î´Î¯Î½Î¿Î½Ï„Î±Î¹
- ÎœÎ·Î½ ÎµÏ†ÎµÏ…ÏÎ¯ÏƒÎºÎµÎ¹Ï‚ Î® Î¼Î·Î½ Ï…Ï€Î¿Î¸Î­Ï„ÎµÎ¹Ï‚ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±

Î£Î¤Î¥Î› Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
- Î•Ï€Î¯ÏƒÎ·Î¼Î¿Ï‚ ÎºÎ±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒÏ‚ Ï„ÏŒÎ½Î¿Ï‚
- Î†Î¼ÎµÏƒÎµÏ‚ ÎºÎ±Î¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Î¿Î´Î·Î³Î¯ÎµÏ‚
- Î§Ï‰ÏÎ¯Ï‚ Ï‡Î±Î¹ÏÎµÏ„Î¹ÏƒÎ¼Î¿ÏÏ‚ Î® Ï†Î¹Î»Î¹ÎºÎ­Ï‚ ÎµÎºÏ†ÏÎ¬ÏƒÎµÎ¹Ï‚
- Î”Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ Î¼Îµ ÏƒÎ±Ï†Î® Î²Î®Î¼Î±Ï„Î±
- Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î· Ï‡ÏÎ®ÏƒÎ· emojis (Î¼ÏŒÎ½Î¿ Î³Î¹Î± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚)

Î’Î‘Î£Î™ÎšÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£ (Î¼ÏŒÎ½Î¿ Î±Ï…Ï„Î­Ï‚):
- Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚
- Email: gsofianidis@mitropolitiko.edu.gr
- Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ ÏÏÎµÏ‚: 240 ÏÏÎµÏ‚ Î¼Î­Ï‡ÏÎ¹ 30/4
- Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿, Î¼Î­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±
- Î£ÏÎ¼Î²Î±ÏƒÎ·: Î‘Î½Î­Î²Î±ÏƒÎ¼Î± ÏƒÏ„Î¿ moodle Î¼Î­Ï‡ÏÎ¹ 15/10

ÎŸÎ”Î—Î“Î™Î•Î£:
- ÎœÏ€ÎµÏ‚ ÎºÎ±Ï„ÎµÏ…Î¸ÎµÎ¯Î±Î½ ÏƒÏ„Î¿ Î¸Î­Î¼Î± Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÎµÏÎ¹Ï„Ï„Î¬ Î»ÏŒÎ³Î¹Î±
- Î”ÏÏƒÎµ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ ÎºÎ±Î¹ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÎ¹Î¼ÎµÏ‚ Î¿Î´Î·Î³Î¯ÎµÏ‚
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï€Î¬Î½Ï„Î± Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿ context
- Î‘Î½ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹Ï‚ Î±ÏÎºÎµÏ„Î­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚, ÎºÎ±Ï„ÎµÏÎ¸Ï…Î½Îµ ÏƒÏ„Î¿Î½ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·
- ÎœÎ·Î½ ÎºÎ¬Î½ÎµÎ¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÎµÎºÏ„ÏŒÏ‚ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î³Î¹Î± Î´Î¹ÎµÏ…ÎºÏÎ¯Î½Î¹ÏƒÎ·
- ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹Ï‚ Ï„Î¯Ï„Î»Î¿Ï…Ï‚, Î²Î±Î¸Î¼Î¿ÏÏ‚ Î® Î¬Î»Î»Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Ï€Î¿Ï… Î´ÎµÎ½ Î±Î½Î±Ï†Î­ÏÎ¿Î½Ï„Î±Î¹

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏŒÎ½Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Î´Î¿ÏƒÎ¼Î­Î½ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚."""

    def init_groq_client(self):
        """Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Groq client"""
        try:
            if GROQ_AVAILABLE:
                # Î”Î¿ÎºÎ¹Î¼Î® Î³Î¹Î± API key Î±Ï€ÏŒ streamlit secrets
                api_key = st.secrets.get("GROQ_API_KEY")
                if api_key:
                    return Groq(api_key=api_key)
        except Exception as e:
            st.sidebar.warning(f"Groq API Î¼Î· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿: {str(e)}")
        return None

    def load_qa_data(self) -> List[Dict]:
        """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Q&A"""
        try:
            if os.path.exists('qa_data.json'):
                with open('qa_data.json', 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return self.get_default_qa_data()
        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: {e}")
            return self.get_default_qa_data()

    def get_default_qa_data(self) -> List[Dict]:
        """Î ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±"""
        return [
            {
                "id": 1,
                "category": "Î“ÎµÎ½Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚",
                "question": "Î ÏÏ‚ Î¾ÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¼Î¿Ï… Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î“Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÏ„Îµ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·, ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î· ÏƒÏ„Î¿ gsofianidis@mitropolitiko.edu.gr. Î‘Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ 240 ÏÏÎµÏ‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ ÏƒÎµ Î´Î¿Î¼Î® Ï„Î·Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÎ±Ï‚ Î¼Î­Ï‡ÏÎ¹ 30/4.",
                "keywords": ["Î¾ÎµÎºÎ¹Î½Î¬Ï‰", "Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®", "Î¬ÏƒÎºÎ·ÏƒÎ·", "Î±ÏÏ‡Î®", "Ï€ÏÏ‚"]
            }
        ]

    def find_relevant_context(self, question: str, top_k: int = 3) -> str:
        """RAG: Î’ÏÎµÏ‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Î³Î¹Î± Ï„Î¿ LM"""
        if not self.qa_data:
            return ""

        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚
        scored_items = []
        for item in self.qa_data:
            score = self.calculate_similarity(question, item)
            scored_items.append((item, score))

        # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÏ€Î¹Î»Î¿Î³Î® top_k
        scored_items.sort(key=lambda x: x[1], reverse=True)
        top_items = scored_items[:top_k]

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± context
        context = "Î£Î§Î•Î¤Î™ÎšÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£:\n\n"
        for item, score in top_items:
            if score > 0.1:  # ÎšÏÎ¬Ï„Î± Î¼ÏŒÎ½Î¿ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚
                context += f"Î•ÏÏÏ„Î·ÏƒÎ·: {item['question']}\n"
                context += f"Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: {item['answer']}\n"
                context += f"ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±: {item.get('category', 'Î“ÎµÎ½Î¹ÎºÎ¬')}\n\n"

        return context

    def calculate_similarity(self, question: str, qa_item: Dict) -> float:
        """Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ (Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î­ÎºÎ´Î¿ÏƒÎ·)"""
        question_lower = question.lower()
        qa_question_lower = qa_item['question'].lower()
        qa_answer_lower = qa_item['answer'].lower()

        # Î’Î±ÏƒÎ¹ÎºÎ® Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±
        similarity = difflib.SequenceMatcher(None, question_lower, qa_question_lower).ratio()

        # Keyword matching
        if 'keywords' in qa_item:
            for keyword in qa_item['keywords']:
                if keyword.lower() in question_lower:
                    similarity += 0.3

        # Answer content matching
        question_words = question_lower.split()
        for word in question_words:
            if len(word) > 3 and word in qa_answer_lower:
                similarity += 0.1

        return min(similarity, 1.0)

    def get_groq_response(self, question: str) -> Tuple[str, bool]:
        """Î›Î®ÏˆÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ Groq LM"""
        if not self.groq_client:
            return "", False

        try:
            # Î’ÏÎµÏ‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ context
            context = self.find_relevant_context(question)

            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… user message
            user_message = f"{context}\n\nÎ•Î¡Î©Î¤Î—Î£Î— Î¦ÎŸÎ™Î¤Î—Î¤Î—: {question}"

            # ÎšÎ»Î®ÏƒÎ· ÏƒÏ„Î¿ Groq API
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_message}
                ],
                model="llama-3.1-8b-instant",  # Î“ÏÎ®Î³Î¿ÏÎ¿ ÎºÎ±Î¹ Î´Ï‰ÏÎµÎ¬Î½
                temperature=0.3,  # Î§Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ Î³Î¹Î± Ï€Î¹Î¿ ÎµÏ€Î¯ÏƒÎ·Î¼ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
                max_tokens=800,   # Î£Ï…Î½Ï„Î¿Î¼ÏŒÏ„ÎµÏÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
                top_p=1,
                stream=False
            )

            response = chat_completion.choices[0].message.content
            return response, True

        except Exception as e:
            st.error(f"Î£Ï†Î¬Î»Î¼Î± Groq API: {str(e)}")
            return "", False

    def get_fallback_response(self, question: str) -> str:
        """Fallback ÏƒÏ„Î¿ Ï€Î±Î»Î¹ÏŒ ÏƒÏÏƒÏ„Î·Î¼Î±"""
        if not self.qa_data:
            return "Î›Ï…Ï€Î¬Î¼Î±Î¹, Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±. Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·: gsofianidis@mitropolitiko.edu.gr"

        # Î’ÏÎµÏ‚ Ï„Î·Î½ ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·
        best_match = max(self.qa_data, key=lambda x: self.calculate_similarity(question, x))
        similarity = self.calculate_similarity(question, best_match)

        if similarity > 0.2:
            return best_match['answer']
        else:
            return f"""Î”ÎµÎ½ Î²ÏÎ®ÎºÎ± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.

**Î ÏÎ¿Ï„ÎµÎ¯Î½Ï‰:**
â€¢ Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î½Î± Î±Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÎµÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·
â€¢ Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î±Ï€ÏŒ Ï„Î¹Ï‚ ÏƒÏ…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ sidebar
â€¢ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ **Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·**: gsofianidis@mitropolitiko.edu.gr"""

    def get_response(self, question: str) -> Dict:
        """ÎšÏÏÎ¹Î± Î¼Î­Î¸Î¿Î´Î¿Ï‚ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚"""
        start_time = time.time()

        # Î”Î¿ÎºÎ¹Î¼Î® Î¼Îµ Groq Ï€ÏÏÏ„Î±
        if self.groq_client:
            answer, success = self.get_groq_response(question)
            if success and answer:
                response = {
                    'answer': answer,
                    'confidence': 0.95,  # Î¥ÏˆÎ·Î»Î® ÎµÎ¼Ï€Î¹ÏƒÏ„Î¿ÏƒÏÎ½Î· Î³Î¹Î± LM
                    'source': 'AI Assistant',
                    'response_time': round(time.time() - start_time, 2),
                    'timestamp': datetime.now().strftime("%H:%M")
                }
            else:
                # Fallback
                answer = self.get_fallback_response(question)
                response = {
                    'answer': answer,
                    'confidence': 0.6,
                    'source': 'Knowledge Base',
                    'response_time': round(time.time() - start_time, 2),
                    'timestamp': datetime.now().strftime("%H:%M")
                }
        else:
            # ÎœÏŒÎ½Î¿ fallback
            answer = self.get_fallback_response(question)
            response = {
                'answer': answer,
                'confidence': 0.6,
                'source': 'Knowledge Base',
                'response_time': round(time.time() - start_time, 2),
                'timestamp': datetime.now().strftime("%H:%M")
            }

        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ
        self.conversation_history.append({
            'question': question,
            'response': response,
            'timestamp': datetime.now()
        })

        return response

def show_typing_indicator():
    """Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· typing indicator"""
    typing_placeholder = st.empty()
    typing_placeholder.markdown("""
    <div class="typing-indicator">
        <strong>ğŸ¤– Î£ÎºÎ­Ï†Ï„Î¿Î¼Î±Î¹</strong>
        <div class="typing-dots">
            <span></span>
            <span></span>
            <span></span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    return typing_placeholder

def main():
    # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = AdvancedPracticeChatbot()

    if 'messages' not in st.session_state:
        st.session_state.messages = []

    # Header Î¼Îµ logo
    st.markdown('<div class="logo-container">', unsafe_allow_html=True)

    logo_col, title_col = st.columns([1, 4])

    with logo_col:
        try:
            st.image("https://raw.githubusercontent.com/GiorgosBouh/chatbot.placement/main/MK_LOGO_SEO_1200x630.png", width=140)
        except:
            st.markdown("ğŸ“", unsafe_allow_html=True)

    with title_col:
        st.markdown('<h1 class="main-header">Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ·</h1>', unsafe_allow_html=True)
        st.markdown('<p class="sub-header">ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚ â€¢ Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ® & Î¦Ï…ÏƒÎ¹ÎºÎ® Î‘Î³Ï‰Î³Î®</p>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

    # API Status
    if st.session_state.chatbot.groq_client:
        st.markdown('<div class="api-status">ğŸš€ AI Assistant Î•Î½ÎµÏÎ³ÏŒ</div>', unsafe_allow_html=True)

    # Layout Î¼Îµ ÏƒÏ„Î®Î»ÎµÏ‚
    col1, col2, col3 = st.columns([1, 3, 1])

    with col2:
        # Quick Info Cards
        with st.container():
            quick_col1, quick_col2, quick_col3 = st.columns(3)

            with quick_col1:
                st.markdown("""
                <div class="info-card" style="text-align: center;">
                    <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“… ÎÏÎµÏ‚</h4>
                    <p style="font-size: 1.2rem; font-weight: 600; color: #28a745; margin: 0;">240 ÏÏÎµÏ‚</p>
                    <small style="color: #6c757d;">Î¼Î­Ï‡ÏÎ¹ 30/4</small>
                </div>
                """, unsafe_allow_html=True)

            with quick_col2:
                st.markdown("""
                <div class="info-card" style="text-align: center;">
                    <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“‹ Î£ÏÎ¼Î²Î±ÏƒÎ·</h4>
                    <p style="font-size: 1.2rem; font-weight: 600; color: #ffc107; margin: 0;">Moodle</p>
                    <small style="color: #6c757d;">Î¼Î­Ï‡ÏÎ¹ 15/10</small>
                </div>
                """, unsafe_allow_html=True)

            with quick_col3:
                st.markdown("""
                <div class="info-card" style="text-align: center;">
                    <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">â° Î©ÏÎ¬ÏÎ¹Î¿</h4>
                    <p style="font-size: 1.2rem; font-weight: 600; color: #17a2b8; margin: 0;">Î”Îµ-Î£Î±</p>
                    <small style="color: #6c757d;">Î¼Î­Ï‡ÏÎ¹ 8Ï‰/Î·Î¼Î­ÏÎ±</small>
                </div>
                """, unsafe_allow_html=True)

        # Î’ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î¿ header styling
        st.markdown('<div style="margin-bottom: 2rem;"></div>', unsafe_allow_html=True)

        # Chat Interface
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(f'''
                <div class="user-message">
                    <strong>ğŸ“ Î¦Î¿Î¹Ï„Î·Ï„Î®Ï‚:</strong> {message["content"]}
                </div>
                ''', unsafe_allow_html=True)
            else:
                source = message.get("source", "Knowledge Base")
                confidence = message.get("confidence", 0)
                timestamp = message.get("timestamp", "")
                response_time = message.get("response_time", 0)

                if source == "AI Assistant":
                    # AI Response styling
                    st.markdown(f'''
                    <div class="ai-message">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.8rem;">
                            <strong>ğŸ¤– AI Assistant</strong>
                            <span style="font-size: 0.85rem; opacity: 0.9;">
                                âš¡ {response_time}s â€¢ {timestamp}
                            </span>
                        </div>
                        <div style="line-height: 1.6;">
                            {message["content"]}
                        </div>
                    </div>
                    ''', unsafe_allow_html=True)
                else:
                    # Fallback response styling
                    if confidence > 0.7:
                        conf_class = "confidence-high"
                        conf_icon = "ğŸŸ¢"
                        conf_text = "Î¥ÏˆÎ·Î»Î®"
                    elif confidence > 0.4:
                        conf_class = "confidence-medium"
                        conf_icon = "ğŸŸ¡"
                        conf_text = "ÎœÎ­Ï„ÏÎ¹Î±"
                    else:
                        conf_class = "confidence-low"
                        conf_icon = "ğŸ”´"
                        conf_text = "Î§Î±Î¼Î·Î»Î®"

                    st.markdown(f'''
                    <div class="bot-message {conf_class}">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.8rem;">
                            <strong style="color: #1f4e79;">ğŸ“š Knowledge Base</strong>
                            <span style="font-size: 0.85rem; color: #6c757d;">
                                {conf_icon} {conf_text} â€¢ {timestamp}
                            </span>
                        </div>
                        <div style="line-height: 1.6;">
                            {message["content"]}
                        </div>
                    </div>
                    ''', unsafe_allow_html=True)

        # Input
        st.markdown("<br>", unsafe_allow_html=True)

        with st.form(key='question_form', clear_on_submit=True):
            user_input = st.text_input(
                label="Î“ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚:",
                placeholder="Ï€.Ï‡. Î ÏÏ‚ Î¾ÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                label_visibility="collapsed"
            )

            col_a, col_b, col_c = st.columns([2, 1, 2])
            with col_b:
                submitted = st.form_submit_button("Î‘Ï€Î¿ÏƒÏ„Î¿Î»Î®", use_container_width=True)

        if submitted and user_input.strip():
            # Add user message
            st.session_state.messages.append({"role": "user", "content": user_input.strip()})

            # Show typing indicator Î³Î¹Î± LM responses
            if st.session_state.chatbot.groq_client:
                typing_placeholder = show_typing_indicator()
                time.sleep(1)  # Simulated thinking time
                typing_placeholder.empty()

            # Get bot response
            response = st.session_state.chatbot.get_response(user_input.strip())

            # Add bot message
            st.session_state.messages.append({
                "role": "assistant",
                "content": response['answer'],
                "confidence": response['confidence'],
                "source": response['source'],
                "response_time": response['response_time'],
                "timestamp": response['timestamp']
            })

            st.rerun()

    # Sidebar
    with st.sidebar:
        st.markdown("## ğŸ“ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±")

        st.markdown("""
        **Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚**  
        **Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚**  
        ğŸ“§ gsofianidis@mitropolitiko.edu.gr
        """)

        st.markdown("---")

        # Î£Ï…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
        st.markdown("## â“ Î£Ï…Ï‡Î½Î­Ï‚ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚")

        for question in st.session_state.chatbot.frequent_questions:
            if st.button(question, key=f"faq_{question}", use_container_width=True):
                # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î·Ï‚ ÎµÏÏÏ„Î·ÏƒÎ·Ï‚ ÏƒÏ„Î· ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±
                st.session_state.messages.append({"role": "user", "content": question})

                # Î›Î®ÏˆÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚
                response = st.session_state.chatbot.get_response(question)

                # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response['answer'],
                    "confidence": response['confidence'],
                    "source": response['source'],
                    "response_time": response['response_time'],
                    "timestamp": response['timestamp']
                })

                st.rerun()

        st.markdown("---")

        st.markdown("## ğŸ”— Î§ÏÎ®ÏƒÎ¹Î¼Î¿Î¹ Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Î¹")
        st.link_button("ğŸ›ï¸ Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î™ÎºÎ±Î½ÏŒÏ„Î·Ï„Î±", "https://www.gov.gr/ipiresies/ergasia-kai-asphalise/asphalise/asphalistike-ikanoteta")
        st.link_button("ğŸ“‹ ATLAS", "https://www.atlas.gov.gr/ATLAS/Pages/Home.aspx")
        st.link_button("ğŸ“‘ Î¥Ï€ÎµÏÎ¸Ï…Î½Î· Î”Î®Î»Ï‰ÏƒÎ·", "https://www.gov.gr")

        st.markdown("---")

        # AI Status
        if st.session_state.chatbot.groq_client:
            st.success("ğŸ¤– AI Assistant Î•Î½ÎµÏÎ³ÏŒ")
            st.info("Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Llama 3.1 8B")
        else:
            st.warning("ğŸ“š Knowledge Base Mode")
            st.info("Î“Î¹Î± AI responses, Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Groq API key")

        st.markdown("---")

        if st.button("ğŸ—‘ï¸ ÎÎ­Î± Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

        # Statistics
        if st.checkbox("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"):
            total_conversations = len(st.session_state.chatbot.conversation_history)
            ai_responses = sum(1 for conv in st.session_state.chatbot.conversation_history 
                             if conv['response'].get('source') == 'AI Assistant')
            
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚", total_conversations)
            st.metric("AI Î‘Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚", ai_responses)
            if total_conversations > 0:
                ai_percentage = round((ai_responses / total_conversations) * 100, 1)
                st.metric("AI Success Rate", f"{ai_percentage}%")

    # Footer
    st.markdown("<br><br>", unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div style="text-align: center; color: #6c757d; font-size: 0.9rem; padding: 2rem 0; border-top: 1px solid #e9ecef;">
            ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚ â€¢ Î¤Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚<br>
            <small>Powered by Groq AI â€¢ Î“Î¹Î± Ï„ÎµÏ‡Î½Î¹ÎºÎ® Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·</small>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()