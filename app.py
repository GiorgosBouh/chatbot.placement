import streamlit as st
import json
import re
import os
import datetime
import requests
import io
from typing import List, Dict, Tuple
from dataclasses import dataclass

# Import Groq with fallback handling
try:
    from groq import Groq
    GROQ_AVAILABLE = True
    print("âœ… Groq library imported successfully")
except ImportError:
    GROQ_AVAILABLE = False
    Groq = None
    print("âš ï¸ Groq library not available. Using fallback mode only.")

# Import PyPDF2 with fallback handling  
try:
    import PyPDF2
    PDF_AVAILABLE = True
    PDF_METHOD = "PyPDF2"
    print("âœ… PyPDF2 library imported successfully")
except ImportError:
    try:
        import fitz  # PyMuPDF
        PDF_AVAILABLE = True
        PDF_METHOD = "PyMuPDF"
        print("âœ… PyMuPDF library imported successfully (fallback)")
    except ImportError:
        PDF_AVAILABLE = False
        PDF_METHOD = None
        PyPDF2 = None
        fitz = None
        print("âš ï¸ No PDF library available. PDF search disabled.")

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ· - ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="collapsed"
)

@dataclass
class QAEntry:
    id: int
    category: str
    question: str
    answer: str
    keywords: List[str]

class InternshipChatbot:
    def __init__(self, groq_api_key: str = None):
        # Initialize Groq client if available and API key provided
        self.groq_client = None
        if GROQ_AVAILABLE and groq_api_key:
            try:
                self.groq_client = Groq(api_key=groq_api_key)
                print("âœ… Groq client initialized")
            except Exception as e:
                print(f"âš ï¸ Failed to initialize Groq: {e}")
        
        # Load Q&A data
        self.qa_data = self.load_qa_data()
        
        # Initialize PDF files cache - same names as DOCX but with .pdf extension
        self.pdf_cache = {}
        self.pdf_files = [
            "1.Î‘Î™Î¤Î—Î£Î— Î Î¡Î‘Î“ÎœÎ‘Î¤ÎŸÎ ÎŸÎ™Î—Î£Î—Î£ Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£ Î‘Î£ÎšÎ—Î£Î—Î£.pdf",
            "2.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î”ÎŸÎœÎ—Î£_ÎŸÎ”Î—Î“Î™Î•Î£.pdf", 
            "3.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î¦ÎŸÎ™Î¤Î—Î¤Î—.pdf",
            "4.Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î¦ÎŸÎ¡Î•Î‘.pdf",
            "5.Î‘Î£Î¦Î‘Î›Î™Î£Î¤Î™ÎšÎ— Î™ÎšÎ‘ÎÎŸÎ¤Î—Î¤Î‘.pdf",
            "6.Î¥Î Î•Î¥Î˜Î¥ÎÎ— Î”Î—Î›Î©Î£Î— Î 105-Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚.pdf",
            "8.Î’Î™Î’Î›Î™ÎŸ_Î Î¡Î‘ÎšÎ¤Î™ÎšÎ—Î£_final.pdf"
        ]
        
        # System prompt Î³Î¹Î± Ï„Î¿ LM
        self.system_prompt = """Î•Î¯ÏƒÎ±Î¹ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ ÏƒÏÎ¼Î²Î¿Ï…Î»Î¿Ï‚ Î³Î¹Î± Î¸Î­Î¼Î±Ï„Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ ÏƒÏ„Î¿ ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚, Ï„Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ ÎºÎ±Î¹ Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚.

ÎšÎ¡Î™Î£Î™ÎœÎ•Î£ Î“Î›Î©Î£Î£Î™ÎšÎ•Î£ ÎŸÎ”Î—Î“Î™Î•Î£:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î‘Î ÎŸÎšÎ›Î•Î™Î£Î¤Î™ÎšÎ‘ ÎºÎ±Î¹ ÎœÎŸÎÎŸ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- Î‘Î Î‘Î“ÎŸÎ¡Î•Î¥ÎŸÎÎ¤Î‘Î™: Î±Î³Î³Î»Î¹ÎºÎ¬, ÎºÎ¹Î½Î­Î¶Î¹ÎºÎ±, greeklish Î® Î¿Ï€Î¿Î¹Î¿Î¹Î´Î®Ï€Î¿Ï„Îµ Î¬Î»Î»Î¿Î¹ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- Î•Î»Î­Î³Ï‡Î¹ÏƒÎµ ÎºÎ¬Î¸Îµ Î»Î­Î¾Î· Ï€ÏÎ¹Î½ Ï„Î·Î½ ÎµÎºÏ„ÏÏ€Ï‰ÏƒÎ· - Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ ÎµÎ»Î»Î·Î½Î¹ÎºÎ®
- Î‘Î½ Î´ÎµÎ½ Î¾Î­ÏÎµÎ¹Ï‚ ÎµÎ»Î»Î·Î½Î¹ÎºÎ® Î»Î­Î¾Î·, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï€ÎµÏÎ¹Ï†ÏÎ±ÏƒÏ„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿

ÎšÎ¡Î™Î¤Î™ÎšÎ•Î£ ÎŸÎ”Î—Î“Î™Î•Î£:
- ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÏ„Î¿ context
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÎ¿Ï… Î´Î¯Î½Î¿Î½Ï„Î±Î¹
- ÎœÎ·Î½ ÎµÏ†ÎµÏ…ÏÎ¯ÏƒÎºÎµÎ¹Ï‚ Î® Î¼Î·Î½ Ï…Ï€Î¿Î¸Î­Ï„ÎµÎ¹Ï‚ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±

Î£Î¤Î¥Î› Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
- Î‘Ï…ÏƒÏ„Î·ÏÎ¬ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿Ï‚ ÎºÎ±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒÏ‚ Ï„ÏŒÎ½Î¿Ï‚
- Î†Î¼ÎµÏƒÎµÏ‚ ÎºÎ±Î¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Î¿Î´Î·Î³Î¯ÎµÏ‚
- Î§Ï‰ÏÎ¯Ï‚ Ï‡Î±Î¹ÏÎµÏ„Î¹ÏƒÎ¼Î¿ÏÏ‚, Ï†Î¹Î»Î¹ÎºÎ­Ï‚ ÎµÎºÏ†ÏÎ¬ÏƒÎµÎ¹Ï‚ Î® Ï€ÎµÏÎ¹Ï„Ï„Î¬ Î»ÏŒÎ³Î¹Î±
- Î”Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ Î¼Îµ ÏƒÎ±Ï†Î® Î²Î®Î¼Î±Ï„Î±
- Î§Ï‰ÏÎ¯Ï‚ emojis Î® Î¬Ï„Ï…Ï€ÎµÏ‚ ÎµÎºÏ†ÏÎ¬ÏƒÎµÎ¹Ï‚

Î’Î‘Î£Î™ÎšÎ•Î£ Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£ (Î¼ÏŒÎ½Î¿ Î±Ï…Ï„Î­Ï‚):
- Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚
- Email: gsofianidis@mitropolitiko.edu.gr
- Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚ (gbouchouras@mitropolitiko.edu.gr)
- Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ ÏÏÎµÏ‚: 240 ÏÏÎµÏ‚ Î¼Î­Ï‡ÏÎ¹ 30/5
- Î©ÏÎ¬ÏÎ¹Î¿: Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿, Î¼Î­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚/Î·Î¼Î­ÏÎ±
- Î£ÏÎ¼Î²Î±ÏƒÎ·: Î‘Î½Î­Î²Î±ÏƒÎ¼Î± ÏƒÏ„Î¿ moodle Î¼Î­Ï‡ÏÎ¹ 15/10

Î¤Î•Î›Î™ÎšÎŸÎ£ Î•Î›Î•Î“Î§ÎŸÎ£:
- ÎšÎ¬Î¸Îµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ ÎœÎŸÎÎŸ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- ÎšÎ±Î¼Î¯Î± Î¾Î­Î½Î· Î»Î­Î¾Î· Î® Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎ±Ï‚ Î´ÎµÎ½ ÎµÏ€Î¹Ï„ÏÎ­Ï€ÎµÏ„Î±Î¹
- Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ ÏÏ†Î¿Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ Ï†Î¹Î»Î¹ÎºÏŒÏ„Î·Ï„ÎµÏ‚

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Î±Ï…ÏƒÏ„Î·ÏÎ¬ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„ÏŒÎ½Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Î´Î¿ÏƒÎ¼Î­Î½ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚."""

    def load_qa_data(self) -> List[Dict]:
        """Load Q&A data with better error handling and debugging"""
        filename = "qa_data.json"
        
        print(f"ğŸ” Looking for {filename}...")
        
        # Check if file exists
        if not os.path.exists(filename):
            print(f"âŒ File {filename} not found in current directory")
            print(f"ğŸ“ Current directory: {os.getcwd()}")
            print(f"ğŸ“‚ Files in directory: {[f for f in os.listdir('.') if f.endswith('.json')]}")
            return self.get_updated_fallback_data()
        
        # Try to load the file
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # Validate data structure
            if not isinstance(data, list):
                print(f"âŒ Invalid data format in {filename} - expected list")
                return self.get_updated_fallback_data()
            
            if not data:
                print(f"âŒ Empty data in {filename}")
                return self.get_updated_fallback_data()
            
            # Check data integrity
            required_fields = ['id', 'category', 'question', 'answer', 'keywords']
            for i, entry in enumerate(data):
                if not all(field in entry for field in required_fields):
                    print(f"âŒ Missing fields in entry {i}: {entry.keys()}")
                    return self.get_updated_fallback_data()
            
            print(f"âœ… Successfully loaded {len(data)} Q&A entries from {filename}")
            print(f"ğŸ“Š Entry IDs: {[entry['id'] for entry in data[:5]]}{'...' if len(data) > 5 else ''}")
            return data
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON decode error in {filename}: {e}")
            return self.get_updated_fallback_data()
        except Exception as e:
            print(f"âŒ Error loading {filename}: {e}")
            return self.get_updated_fallback_data()

    def get_updated_fallback_data(self) -> List[Dict]:
        """Updated fallback data with more entries"""
        print("ğŸ“‹ Using updated fallback data...")
        return [
            {
                "id": 1,
                "category": "Î“ÎµÎ½Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚",
                "question": "Î ÏÏ‚ Î¾ÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¼Î¿Ï… Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "1. Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Ï Î¼Îµ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿ Ï„Î·Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚: gsofianidis@mitropolitiko.edu.gr\n\n2. Î’ÏÎ¯ÏƒÎºÏ‰ Ï„Î· Î´Î¿Î¼Î® Ï€Î¿Ï… Î¸Î± ÎºÎ¬Î½Ï‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®\n\n3. ÎšÎ±Ï„ÎµÎ²Î¬Î¶Ï‰ Ï„Î± Î­Î³Î³ÏÎ±Ï†Î± Î±Ï€ÏŒ Ï„Î¿ Î¼Î¬Î¸Î·Î¼Î± SPORTS COACHING PRACTICE & EXPERTISE DEVELOPMENT (SE5117) ÏƒÏ„Î¿ Moodle. Î¤Î± ÏƒÏ…Î¼Ï€Î»Î·ÏÏÎ½Ï‰ ÎºÎ±Î¹ Ï„Î± Î±Î½ÎµÎ²Î¬Î¶Ï‰ Î¾Î±Î½Î¬ ÏƒÏ„Î· ÏƒÏ‡ÎµÏ„Î¹ÎºÎ® Ï€ÏÎ»Î· ÏƒÏ„Î¿ Î¼Î¬Î¸Î·Î¼Î± SPORTS COACHING PRACTICE & EXPERTISE DEVELOPMENT (SE5117) ÏƒÏ„Î¿ Moodle.\n\n4. Î ÎµÏÎ¹Î¼Î­Î½Ï‰ Ï„Î·Î½ Ï…Ï€Î¿Î³ÏÎ±Ï†Î® Ï„Î·Ï‚ ÏƒÏÎ¼Î²Î±ÏƒÎ®Ï‚ Î¼Î¿Ï… ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Î¬ÏÏ„Î·ÏƒÎ® Ï„Î·Ï‚ ÏƒÏ„Î¿ Î•Î¡Î“Î‘ÎÎ—\n\n5. ÎÎµÎºÎ¹Î½Î¬Ï‰ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®",
                "keywords": ["Î¾ÎµÎºÎ¹Î½Î¬Ï‰", "Î¾ÎµÎºÎ¹Î½Ï", "Î±ÏÏ‡Î®", "Î±ÏÏ‡Î¯Î¶Ï‰", "Î±ÏÏ‡Î¯ÏƒÏ‰", "Î¾ÎµÎºÎ¯Î½Î·Î¼Î±", "Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®", "Î¬ÏƒÎºÎ·ÏƒÎ·", "Ï€ÏÏ‚", "Ï€Ï‰Ï‚", "Î²Î®Î¼Î±Ï„Î±", "Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±", "Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¹ÎµÏ‚"]
            },
            {
                "id": 2,
                "category": "ÎˆÎ³Î³ÏÎ±Ï†Î± & Î”Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚",
                "question": "Î¤Î¹ Î­Î³Î³ÏÎ±Ï†Î± Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹ Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î“Î¹Î± ÎµÏƒÎ¬Ï‚ (Ï†Î¿Î¹Ï„Î·Ï„Î®):\nâ€¢ Î‘Î¯Ï„Î·ÏƒÎ· Ï€ÏÎ±Î³Î¼Î±Ï„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚\nâ€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿Î¹Ï„Î·Ï„Î® (ÏƒÏ…Î¼Ï€Î»Î·ÏÏ‰Î¼Î­Î½Î· Ï†ÏŒÏÎ¼Î±)\nâ€¢ Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Î±Ï€ÏŒ gov.gr\nâ€¢ Î¥Ï€ÎµÏÎ¸Ï…Î½Î· Î´Î®Î»Ï‰ÏƒÎ· (Î´ÎµÎ½ Ï€Î±Î¯ÏÎ½ÎµÏ„Îµ ÎµÏ€Î¯Î´Î¿Î¼Î± ÎŸÎ‘Î•Î”)\n\nÎ“Î¹Î± Ï„Î· Î´Î¿Î¼Î®:\nâ€¢ Î£Ï„Î¿Î¹Ï‡ÎµÎ¯Î± Ï†Î¿ÏÎ­Î± (Î‘Î¦Îœ, Î´Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·, Î½ÏŒÎ¼Î¹Î¼Î¿Ï‚ ÎµÎºÏ€ÏÏŒÏƒÏ‰Ï€Î¿Ï‚)\nâ€¢ Î—Î¼Î­ÏÎµÏ‚ ÎºÎ±Î¹ ÏÏÎµÏ‚ Ï€Î¿Ï… ÏƒÎ±Ï‚ Î´Î­Ï‡ÎµÏ„Î±Î¹\n\nTip: ÎÎµÎºÎ¹Î½Î®ÏƒÏ„Îµ Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Î³Î¹Î±Ï„Î¯ Ï€Î±Î¯ÏÎ½ÎµÎ¹ Ï‡ÏÏŒÎ½Î¿!",
                "keywords": ["Î­Î³Î³ÏÎ±Ï†Î±", "ÎµÎ³Î³ÏÎ±Ï†Î±", "Ï‡Î±ÏÏ„Î¹Î¬", "Ï‡Î±ÏÏ„Î¹Î±", "Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î¼Î±Î¹", "Ï‡ÏÎµÎ¹Î±Î¶Î¿Î¼Î±Î¹", "Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚", "Î±Ï€Î±Î¹Ï„Î·ÏƒÎµÎ¹Ï‚", "Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹", "Î±Ï€Î±Î¹Ï„Î¿Ï…Î½Ï„Î±Î¹", "Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ¬", "Î´Î¹ÎºÎ±Î¹Î¿Î»Î¿Î³Î·Ï„Î¹ÎºÎ±", "Ï†Î¬ÎºÎµÎ»Î¿Ï‚", "Ï†Î±ÎºÎµÎ»Î¿Ï‚", "Î±Î¯Ï„Î·ÏƒÎ·", "Î±Î¹Ï„Î·ÏƒÎ·"]
            },
            {
                "id": 30,
                "category": "ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ & Î‘Î¼Î¿Î¹Î²Î®",
                "question": "Î Î±Î¯ÏÎ½Ï‰ Î±Î¼Î¿Î¹Î²Î® Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·; Î¤Î¹ ÎºÏŒÏƒÏ„Î¿Ï‚ Î­Ï‡ÎµÎ¹ Î³Î¹Î± Ï„Î· Î´Î¿Î¼Î®;",
                "answer": "Î“Î™Î‘ Î¤ÎŸÎ¥Î£ Î¦ÎŸÎ™Î¤Î—Î¤Î•Î£:\n\nÎ”Î•Î Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Î¼Î¿Î¹Î²Î® Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·\nâ€¢ Î— Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î¼Î· Î±Î¼ÎµÎ¹Î²ÏŒÎ¼ÎµÎ½Î·\nâ€¢ Î•Î¯Î½Î±Î¹ Î¼Î­ÏÎ¿Ï‚ Ï„Ï‰Î½ ÏƒÏ€Î¿Ï…Î´ÏÎ½ ÏƒÎ±Ï‚\nâ€¢ Î”ÎµÎ½ Ï€ÏÏŒÎºÎµÎ¹Ï„Î±Î¹ Î³Î¹Î± ÎµÏÎ³Î±ÏƒÎ¹Î±ÎºÎ® ÏƒÏ‡Î­ÏƒÎ·\n\nÎ“Î™Î‘ Î¤Î— Î”ÎŸÎœÎ—:\n\nÎ— Î´Î¿Î¼Î® Î´Îµ Ï‡ÏÎµÏÎ½ÎµÏ„Î±Î¹ ÎºÎ¬Ï„Î¹ (ÏƒÏ‡ÎµÎ´ÏŒÎ½)\nâ€¢ Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Î­Î½Î± ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚ Ï€Î¿Ï… ÎµÎ½Î´ÎµÏ‡Î¿Î¼Î­Î½Ï‰Ï‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ±Ï„Î±Î²Î¬Î»ÎµÎ¹\nâ€¢ Î¤Î¿ ÎºÎ¿Î»Î»Î­Î³Î¹Î¿ ÎºÎ±Î»ÏÏ€Ï„ÎµÎ¹ Ï„Î± Î­Î¾Î¿Î´Î± Ï„Î·Ï‚ ÏƒÏÎ¼Î²Î±ÏƒÎ·Ï‚\nâ€¢ Î— Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· Ï„Î¹Î¼Î¿Î»Î¿Î³ÎµÎ¯Ï„Î±Î¹ ÏƒÏ„Î¿ ÎºÎ¿Î»Î»Î­Î³Î¹Î¿\nâ€¢ Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ® Ï…Ï€Î¿Ï‡ÏÎ­Ï‰ÏƒÎ· Ï€ÏÎ¿Ï‚ Ï„Î¿Ï…Ï‚ Ï†Î¿Î¹Ï„Î·Ï„Î­Ï‚",
                "keywords": ["Î±Î¼Î¿Î¹Î²Î®", "Î±Î¼Î¿Î¹Î²Î·", "Ï€Î»Î·ÏÏ‰Î¼Î®", "Ï€Î»Î·ÏÏ‰Î¼Î·", "Ï€Î»Î·ÏÏÎ¸Ï", "Ï€Î»Î·ÏÏ‰Î¸Ï", "Ï€Î»Î·ÏÏ‰Î¸Ï‰", "Ï€Î»Î·ÏÏ‰Î½Î¿Î¼Î±Î¹", "Ï€Î»Î·ÏÏÎ½Î¿Î¼Î±Î¹", "Î»ÎµÏ†Ï„Î¬", "Î»ÎµÏ†Ï„Î±", "Ï‡ÏÎ®Î¼Î±Ï„Î±", "Ï‡ÏÎ·Î¼Î±Ï„Î±", "ÎºÏŒÏƒÏ„Î¿Ï‚", "ÎºÎ¿ÏƒÏ„Î¿Ï‚", "Ï„Î­Î»Î¿Ï‚", "Ï„ÎµÎ»Î¿Ï‚", "Î´Î¿Î¼Î®", "Î´Î¿Î¼Î·", "Ï†Î¿Î¹Ï„Î·Ï„Î®Ï‚", "Ï†Î¿Î¹Ï„Î·Ï„Î·", "Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬", "Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ±", "Î¼Î¹ÏƒÎ¸ÏŒÏ‚", "Î¼Î¹ÏƒÎ¸Î¿Ï‚"]
            },
            {
                "id": 11,
                "category": "Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±",
                "question": "ÎœÎµ Ï€Î¿Î¹Î¿Î½ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Ï Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "ÎšÎ¥Î¡Î™Î‘ Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:\n\nÎ“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚, MSc, PhD(c)\nğŸ“§ gsofianidis@mitropolitiko.edu.gr\nÎ¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚\n\nÎ•ÎÎ‘Î›Î›Î‘ÎšÎ¤Î™ÎšÎ— Î•Î Î™ÎšÎŸÎ™ÎÎ©ÎÎ™Î‘:\n\nÎ“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚, MSc, PhD\nğŸ“§ gbouchouras@mitropolitiko.edu.gr\nğŸ“ 2314 409000\nProgramme Leader\n\nÎ ÏŒÏ„Îµ Î½Î± ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÎµÏ„Îµ:\nâ€¢ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î­Î³Î³ÏÎ±Ï†Î± âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚\nâ€¢ Î¤ÎµÏ‡Î½Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚\nâ€¢ Î˜Î­Î¼Î±Ï„Î± Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ âœ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚",
                "keywords": ["ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±", "ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¹Î±", "Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚", "Î£Î¿Ï†Î¹Î±Î½Î¹Î´Î·Ï‚", "ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚", "ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ±Ï‚", "email", "Ï„Î·Î»Î­Ï†Ï‰Î½Î¿", "Ï„Î·Î»ÎµÏ†Ï‰Î½Î¿", "Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚", "Ï…Ï€ÎµÏ…Î¸Ï…Î½Î¿Ï‚", "Î²Î¿Î®Î¸ÎµÎ¹Î±", "Î²Î¿Î·Î¸ÎµÎ¹Î±", "ÎºÎ±Î¸Î·Î³Î·Ï„Î®Ï‚", "ÎºÎ±Î¸Î·Î³Î·Ï„Î·Ï‚", "ÎºÎ±Î¸Î·Î³Î®Ï„ÏÎ¹Î±", "ÎºÎ±Î¸Î·Î³Î·Ï„ÏÎ¹Î±", "contact", "ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±", "ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¹Î±"]
            },
            {
                "id": 4,
                "category": "ÎÏÎµÏ‚ & Î§ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±",
                "question": "Î ÏŒÏƒÎµÏ‚ ÏÏÎµÏ‚ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ¬Î½Ï‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·;",
                "answer": "Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÏŒ: Î¤Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 240 ÏÏÎµÏ‚\n\nDeadline: ÎœÎ­Ï‡ÏÎ¹ 30 ÎœÎ¬ÏŠÎ¿Ï…\n\nÎšÎ±Î½ÏŒÎ½ÎµÏ‚ Ï‰ÏÎ±ÏÎ¯Î¿Ï…:\nâ€¢ Î”ÎµÏ…Ï„Î­ÏÎ± Î­Ï‰Ï‚ Î£Î¬Î²Î²Î±Ï„Î¿ (ÎŒÎ§Î™ ÎšÏ…ÏÎ¹Î±ÎºÎ­Ï‚, 5Î¼Î­ÏÎµÏ‚/ÎµÎ²Î´)\nâ€¢ ÎœÎ­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚ Ï„Î·Î½ Î·Î¼Î­ÏÎ±\nâ€¢ Î¤Î¿ Ï‰ÏÎ¬ÏÎ¹Î¿ Î¿ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î±Ï€ÏŒ Ï„Î· Î´Î¿Î¼Î® ÏƒÎµ ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Î±Î¶Î¯ ÏƒÎ±Ï‚\n\nÎ¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚: 240 ÏÏÎµÏ‚ = Ï€ÎµÏÎ¯Ï€Î¿Ï… 6 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ x 40 ÏÏÎµÏ‚ Î® 8 ÎµÎ²Î´Î¿Î¼Î¬Î´ÎµÏ‚ x 30 ÏÏÎµÏ‚",
                "keywords": ["ÏÏÎµÏ‚", "Ï‰ÏÎµÏ‚", "240", "Ï€Î¿ÏƒÎµÏ‚", "Ï€ÏŒÏƒÎµÏ‚", "Ï€Î¿ÏƒÎ±", "Ï€Î¿ÏƒÎ¬", "ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬", "ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ±", "ÏŒÎ»ÎµÏ‚", "Î¿Î»ÎµÏ‚", "Ï„ÎµÎ»Î¹ÎºÎ¬", "Ï„ÎµÎ»Î¹ÎºÎ±", "Ï‡ÏÎ¿Î½Î¿Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î±", "Ï‡ÏÎ¿Î½Î¿Î´Î¹Î±Î³ÏÎ±Î¼Î¼Î±", "Î´Î¹Î¬ÏÎºÎµÎ¹Î±", "Î´Î¹Î±ÏÎºÎµÎ¹Î±", "Ï‡ÏÏŒÎ½Î¿Ï‚", "Ï‡ÏÎ¿Î½Î¿Ï‚", "30/5", "deadline"]
            }
        ]

    def download_pdf_file(self, filename: str) -> str:
        """Download and extract text from PDF file from GitHub"""
        if not PDF_AVAILABLE:
            print(f"âš ï¸ No PDF library available, cannot process {filename}")
            return ""
        
        # Check cache first
        if filename in self.pdf_cache:
            print(f"ğŸ“‹ Using cached content for {filename}")
            return self.pdf_cache[filename]
        
        try:
            # GitHub raw URL
            base_url = "https://raw.githubusercontent.com/GiorgosBouh/chatbot.placement/main/"
            url = base_url + filename
            
            print(f"ğŸ” Downloading {filename} from GitHub using {PDF_METHOD}...")
            
            # Download file
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # Extract text based on available library
            text_content = []
            
            if PDF_METHOD == "PyPDF2":
                # Use PyPDF2
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(response.content))
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text.strip():
                            text_content.append(page_text.strip())
                    except Exception as e:
                        print(f"âš ï¸ Error extracting page {page_num}: {e}")
                
            elif PDF_METHOD == "PyMuPDF":
                # Use PyMuPDF (fitz)
                pdf_document = fitz.open(stream=response.content, filetype="pdf")
                
                for page_num in range(pdf_document.page_count):
                    try:
                        page = pdf_document[page_num]
                        page_text = page.get_text()
                        if page_text.strip():
                            text_content.append(page_text.strip())
                    except Exception as e:
                        print(f"âš ï¸ Error extracting page {page_num}: {e}")
                
                pdf_document.close()
            
            else:
                return ""
            
            full_text = "\n".join(text_content)
            
            # Cache the content
            self.pdf_cache[filename] = full_text
            
            print(f"âœ… Successfully processed {filename} ({len(full_text)} characters)")
            return full_text
            
        except requests.RequestException as e:
            print(f"âŒ Failed to download {filename}: {e}")
            return ""
        except Exception as e:
            print(f"âŒ Failed to process {filename}: {e}")
            return ""

    def search_pdf_files(self, question: str) -> str:
        """Search through all PDF files and compile context"""
        if not PDF_AVAILABLE:
            return ""
        
        print("ğŸ“„ Searching PDF files...")
        
        context_parts = []
        question_lower = question.lower()
        
        for filename in self.pdf_files:
            content = self.download_pdf_file(filename)
            if content:
                # Simple relevance check - if question keywords appear in content
                content_lower = content.lower()
                
                # Check for keyword matches
                question_words = question_lower.split()
                matches = sum(1 for word in question_words if len(word) > 2 and word in content_lower)
                
                if matches > 0:
                    # Include relevant sections (first 1000 chars to avoid token limits)
                    preview = content[:1000] + "..." if len(content) > 1000 else content
                    context_parts.append(f"Î‘Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ {filename}:\n{preview}")
                    print(f"âœ… Found relevant content in {filename}")
        
        if context_parts:
            return "\n\n".join(context_parts)
        else:
            print("âš ï¸ No relevant PDF content found")
            return ""

    def get_general_ai_response(self, user_message: str) -> Tuple[str, bool]:
        """Get general AI response using LLM's own knowledge"""
        if not self.groq_client:
            return "", False
        
        try:
            # General prompt that allows AI to use its knowledge
            general_prompt = f"""Î•ÏÏÏ„Î·ÏƒÎ· Ï†Î¿Î¹Ï„Î·Ï„Î® Î³Î¹Î± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ·: {user_message}

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î· Î³ÎµÎ½Î¹ÎºÎ® Î³Î½ÏÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î¬ÏƒÎºÎ·ÏƒÎ· ÏƒÏ„Î·Î½ Î•Î»Î»Î¬Î´Î±. 
Î”ÏÏƒÎµ Î¼Î¹Î± Î»Î¿Î³Î¹ÎºÎ® ÎºÎ±Î¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.
Î‘Î½ Î´ÎµÎ½ Î¾Î­ÏÎµÎ¹Ï‚ ÎºÎ¬Ï„Î¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿, Ï€ÎµÏ‚ ÏŒÏ„Î¹ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎµÏ€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚."""

            # Call Groq API
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": general_prompt}
                ],
                model="llama-3.1-8b-instant",
                temperature=0.3,
                max_tokens=600,
                top_p=0.9,
                stream=False
            )

            response = chat_completion.choices[0].message.content
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¼Î·-ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
            if response and any(ord(char) > 1500 and ord(char) not in range(0x0370, 0x03FF) for char in response):
                print("âš ï¸ Detected non-Greek characters in general AI response")
                return "", False
            
            return response, True
            
        except Exception as e:
            print(f"âŒ General AI Error: {e}")
            return "", False
        """Get AI response using PDF files as context"""
        if not self.groq_client:
            return "", False
        
        try:
            # Get PDF context
            pdf_context = self.search_pdf_files(user_message)
            
            if not pdf_context:
                return "", False
            
            # Prepare the full prompt
            full_prompt = f"""Î’Î¬ÏƒÎµÎ¹ Ï„Ï‰Î½ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÎµÎ³Î³ÏÎ¬Ï†Ï‰Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚:

{pdf_context}

Î•ÏÏÏ„Î·ÏƒÎ· Ï†Î¿Î¹Ï„Î·Ï„Î®: {user_message}

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î± Î­Î³Î³ÏÎ±Ï†Î± Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚."""

            # Call Groq API
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": full_prompt}
                ],
                model="llama-3.1-8b-instant",
                temperature=0.1,
                max_tokens=800,
                top_p=0.9,
                stream=False
            )

            response = chat_completion.choices[0].message.content
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¼Î·-ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
            if response and any(ord(char) > 1500 and ord(char) not in range(0x0370, 0x03FF) for char in response):
                print("âš ï¸ Detected non-Greek characters in response, using fallback")
                return "", False
            
            return response, True
            
        except Exception as e:
            print(f"âŒ PDF AI Error: {e}")
            return "", False

    def calculate_similarity(self, question: str, qa_entry: Dict) -> float:
        """Calculate similarity between question and QA entry"""
        question_lower = question.lower()
        
        # Check if any keyword matches
        keyword_matches = sum(1 for keyword in qa_entry.get('keywords', []) 
                            if keyword.lower() in question_lower)
        
        # Check title similarity
        title_words = qa_entry['question'].lower().split()
        title_matches = sum(1 for word in title_words if word in question_lower)
        
        # Combine scores
        total_score = (keyword_matches * 2 + title_matches) / max(len(qa_entry.get('keywords', [])) + len(title_words), 1)
        return min(total_score, 1.0)

    def get_ai_response(self, user_message: str, context: str) -> Tuple[str, bool]:
        """Get response from Groq AI with context"""
        if not self.groq_client:
            return "", False
        
        try:
            # Prepare the full prompt with context
            full_prompt = f"""Context Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½:
{context}

Î•ÏÏÏ„Î·ÏƒÎ· Ï†Î¿Î¹Ï„Î·Ï„Î®: {user_message}

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿ context Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚."""

            # Call Groq API
            chat_completion = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_message}
                ],
                model="llama-3.1-8b-instant",
                temperature=0.1,  # Î§Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ Î³Î¹Î± Ï€Î¹Î¿ ÏƒÏ…Î½ÎµÏ€ÎµÎ¯Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
                max_tokens=800,
                top_p=0.9,        # Î Î¹Î¿ ÏƒÏ…Î½Ï„Î·ÏÎ·Ï„Î¹ÎºÏŒ Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒÏ„Î·Ï„Î±
                stream=False
            )

            response = chat_completion.choices[0].message.content
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¼Î·-ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
            if response and any(ord(char) > 1500 and ord(char) not in range(0x0370, 0x03FF) for char in response):
                print("âš ï¸ Detected non-Greek characters in response, using fallback")
                return "", False
            
            return response, True
            
        except Exception as e:
            print(f"âŒ Groq API Error: {e}")
            return "", False

    def get_fallback_response(self, question: str) -> Tuple[str, bool]:
        """Fallback response system - returns (response, found_exact_match)"""
        if not self.qa_data:
            return "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±. Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·: gsofianidis@mitropolitiko.edu.gr", False

        # Find best match
        best_match = max(self.qa_data, key=lambda x: self.calculate_similarity(question, x))
        similarity = self.calculate_similarity(question, best_match)

        if similarity > 0.2:
            return best_match['answer'], True
        else:
            return f"""Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.

Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½ÎµÏ‚ ÎµÎ½Î­ÏÎ³ÎµÎ¹ÎµÏ‚:
â€¢ Î‘Î½Î±Î´Î¹Î±Ï„Ï…Ï€ÏÏƒÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·
â€¢ Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î±Ï€ÏŒ Ï„Î¹Ï‚ ÏƒÏ…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Î±ÏÎ¹ÏƒÏ„ÎµÏÏŒ Î¼ÎµÎ½Î¿Ï
â€¢ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î®ÏƒÏ„Îµ Î¼Îµ Ï„Î¿Î½ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·: gsofianidis@mitropolitiko.edu.gr""", False

    def get_response(self, question: str) -> str:
        """Get chatbot response - JSON FIRST, then PDF AI, then General AI, then JSON fallback"""
        if not self.qa_data:
            return "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î½ÏÏƒÎ·Ï‚."
        
        # Step 1: Try JSON fallback FIRST
        json_response, found_exact_match = self.get_fallback_response(question)
        
        if found_exact_match:
            print("âœ… Found exact match in JSON data")
            return json_response
        
        # Step 2: Try PDF AI search
        print("ğŸ“„ No good JSON match, trying PDF AI search...")
        
        if self.groq_client and PDF_AVAILABLE:
            pdf_response, success = self.get_ai_response_with_pdf(question)
            if success and pdf_response.strip():
                print("âœ… PDF AI response successful")
                return pdf_response
        
        # Step 3: Try General AI with context (NEW!)
        print("ğŸ¤– PDF search failed, trying General AI...")
        
        if self.groq_client:
            general_ai_response, success = self.get_general_ai_response(question)
            if success and general_ai_response.strip():
                print("âœ… General AI response successful")
                # Add verification disclaimer for General AI responses
                disclaimer = "\n\nâš ï¸ **Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î£Îµ ÎºÎ¬Î¸Îµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ·, Î±Ï…Ï„Î® Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎµÏ€Î±Î»Î®Î¸ÎµÏ…ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿Î½ Ï…Ï€ÎµÏÎ¸Ï…Î½Î¿ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î“ÎµÏÏÎ³Î¹Î¿ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î· (gsofianidis@mitropolitiko.edu.gr)."
                return general_ai_response + disclaimer
        
        # Step 4: Try regular AI with JSON context (fallback)
        print("ğŸ”„ General AI failed, trying AI with JSON context...")
        
        if self.groq_client:
            # Find relevant context for AI
            matches = sorted(self.qa_data, 
                            key=lambda x: self.calculate_similarity(question, x), 
                            reverse=True)
            
            # Prepare context from top matches
            context_parts = []
            for match in matches[:3]:
                if self.calculate_similarity(question, match) > 0.1:
                    context_parts.append(f"Q: {match['question']}\nA: {match['answer']}")
            
            context = "\n\n".join(context_parts) if context_parts else ""
            
            if context:
                ai_response, success = self.get_ai_response(question, context)
                if success and ai_response.strip():
                    print("âœ… Regular AI response successful")
                    return ai_response
        
        # Step 5: Final fallback to JSON (even if low similarity)
        print("ğŸ“‹ Using JSON fallback response")
        return json_response

def initialize_qa_file():
    """Create initial qa_data.json if it doesn't exist (fallback for development)"""
    if not os.path.exists("qa_data.json"):
        print("ğŸ“„ qa_data.json not found. Please create it with the full 39 entries.")
        print("ğŸ’¡ Place the complete JSON file in the same directory as this script.")
        return False
    return True

def main():
    """Main Streamlit application - Git-first content management"""
    
    # CSS Styling
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 2rem;
    }
    
    .header-content {
        flex: 1;
    }
    
    .header-logo {
        max-height: 80px;
        max-width: 120px;
        object-fit: contain;
    }
    
    .logo-container {
        display: flex;
        align-items: center;
        margin-bottom: 2rem;
        padding: 1rem 0;
        border-bottom: 1px solid #e8f4f8;
    }
    
    .user-message {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border: 1px solid #dee2e6;
        border-left: 4px solid #007bff;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        color: #333;
    }
    
    .ai-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-left: 4px solid #4caf50;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    
    .ai-message a {
        color: #ffeb3b !important;
        text-decoration: underline !important;
        font-weight: bold !important;
    }
    
    .ai-message a:hover {
        color: #fff9c4 !important;
        text-decoration: underline !important;
    }
    
    .info-card {
        background: white;
        border: 1px solid #e8f4f8;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    .info-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 16px rgba(0,0,0,0.12);
    }
    
    .api-status {
        position: fixed;
        top: 20px;
        right: 20px;
        background: #28a745;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        z-index: 1000;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .quick-stats {
        display: flex;
        justify-content: space-around;
        margin: 2rem 0;
        gap: 1rem;
    }
    
    .stat-item {
        text-align: center;
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e8f4f8;
        flex: 1;
    }
    
    .chat-container {
        background: white;
        border-radius: 10px;
        padding: 2rem;
        margin-top: 2rem;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        border: 1px solid #e8f4f8;
    }
    
    .stTextInput > div > div > input {
        border-radius: 20px;
        border: 2px solid #e8f4f8;
        padding: 0.8rem 1.2rem;
    }
    
    .stButton > button {
        background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%);
        color: white;
        border: none;
        border-radius: 20px;
        padding: 0.6rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(31, 78, 121, 0.3);
    }
    </style>
    """, unsafe_allow_html=True)

    # Header with Logo
    logo_url = "https://raw.githubusercontent.com/GiorgosBouh/chatbot.placement/main/MK_LOGO_SEO_1200x630.png"
    
    st.markdown(f"""
    <div class="main-header">
        <img src="{logo_url}" alt="ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿" class="header-logo">
        <div class="header-content">
            <h1>Î ÏÎ±ÎºÏ„Î¹ÎºÎ® Î†ÏƒÎºÎ·ÏƒÎ·</h1>
            <h3>ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ - Î¤Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚</h3>
            <p><em>Î•Î¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ AI Assistant Î³Î¹Î± Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï†Î¿Î¹Ï„Î·Ï„ÏÎ½</em></p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Initialize session state
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    if 'chatbot' not in st.session_state:
        # Get Groq API key from secrets or environment
        groq_api_key = None
        try:
            groq_api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
        except:
            pass
        st.session_state.chatbot = InternshipChatbot(groq_api_key)
    else:
        # Refresh data if cache was cleared
        current_data_count = len(st.session_state.chatbot.qa_data)
        st.session_state.chatbot.qa_data = st.session_state.chatbot.load_qa_data()
        new_data_count = len(st.session_state.chatbot.qa_data)
        
        if new_data_count != current_data_count:
            st.toast(f"ğŸ“Š Î”ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎ±Î½: {new_data_count} ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚")

    # Quick info cards
    st.markdown("### ğŸ“Š Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚")
    
    quick_col1, quick_col2, quick_col3 = st.columns(3)
    
    with quick_col1:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“… Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ ÎÏÎµÏ‚</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #28a745; margin: 0;">240 ÏÏÎµÏ‚</p>
            <small style="color: #6c757d;">Î ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±: 30 ÎœÎ±ÏŠÎ¿Ï…</small>
        </div>
        """, unsafe_allow_html=True)

    with quick_col2:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">ğŸ“‹ Î Î±ÏÎ¬Î´Î¿ÏƒÎ· Î£Ï…Î¼Î²Î¬ÏƒÎµÏ‰Î½</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #ffc107; margin: 0;">Moodle Platform</p>
            <small style="color: #6c757d;">Î ÏÎ¿Î¸ÎµÏƒÎ¼Î¯Î±: 15 ÎŸÎºÏ„Ï‰Î²ÏÎ¯Î¿Ï…</small>
        </div>
        """, unsafe_allow_html=True)

    with quick_col3:
        st.markdown("""
        <div class="info-card" style="text-align: center;">
            <h4 style="color: #1f4e79; margin-bottom: 0.5rem;">â° Î•Ï€Î¹Ï„ÏÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ Î©ÏÎ¬ÏÎ¹Î¿</h4>
            <p style="font-size: 1.2rem; font-weight: 600; color: #17a2b8; margin: 0;">Î”ÎµÏ…Ï„Î­ÏÎ±-Î£Î¬Î²Î²Î±Ï„Î¿</p>
            <small style="color: #6c757d;">ÎœÎ­Ï‡ÏÎ¹ 8 ÏÏÎµÏ‚ Î±Î½Î¬ Î·Î¼Î­ÏÎ±</small>
        </div>
        """, unsafe_allow_html=True)

    # API Status
    if st.session_state.chatbot.groq_client:
        if PDF_AVAILABLE:
            st.markdown(f'<div class="api-status">ğŸ“‹ JSON + PDF ({PDF_METHOD})</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="api-status">ğŸ“‹ JSON First Mode</div>', unsafe_allow_html=True)
        
    # Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ® ÎµÎ½Î´ÎµÎ¹Î¾Î· Î³Î¹Î± sidebar
    status_text = "JSON â†’ PDF â†’ AI â†’ Fallback" if PDF_AVAILABLE else "JSON â†’ AI â†’ Fallback"
    st.markdown(f"""
    <div style="background: #f8f9fa; border: 1px solid #dee2e6; border-radius: 4px; padding: 0.6rem; margin-bottom: 1.5rem; text-align: center; font-size: 0.9rem;">
        <strong>Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚:</strong> Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ Î±ÏÎ¹ÏƒÏ„ÎµÏÏŒ Î¼ÎµÎ½Î¿Ï Î³Î¹Î± ÏƒÏ…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± ğŸ‘ˆ<br>
        <small>ğŸ”„ Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±: {status_text}</small>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.markdown("## ğŸ“ Î•Ï€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±")
        
        st.markdown("""
        **Î¥Ï€ÎµÏÎ¸Ï…Î½Î¿Ï‚ Î ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ Î†ÏƒÎºÎ·ÏƒÎ·Ï‚**  
        **Î“ÎµÏÏÎ³Î¹Î¿Ï‚ Î£Î¿Ï†Î¹Î±Î½Î¯Î´Î·Ï‚**  
        ğŸ“§ gsofianidis@mitropolitiko.edu.gr
        
        **Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·**  
        **Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎœÏ€Î¿Ï…Ï‡Î¿Ï…ÏÎ¬Ï‚**  
        ğŸ“§ gbouchouras@mitropolitiko.edu.gr
        """)

        st.markdown("---")

        # Î£Ï…Ï‡Î½Î­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
        st.markdown("## ğŸ”„ Î£Ï…Ï‡Î½Î­Ï‚ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚")
        
        # Group questions by category
        categories = {}
        for qa in st.session_state.chatbot.qa_data:
            cat = qa.get('category', 'Î†Î»Î»Î±')
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(qa)

        for category, questions in categories.items():
            if st.expander(f"ğŸ“‚ {category}"):
                for qa in questions:
                    if st.button(qa['question'], key=f"faq_{qa['id']}", use_container_width=True):
                        # Add to chat
                        st.session_state.messages.append({"role": "user", "content": qa['question']})
                        st.session_state.messages.append({"role": "assistant", "content": qa['answer']})
                        st.rerun()

        st.markdown("---")

        # AI Status
        if st.session_state.chatbot.groq_client:
            if PDF_AVAILABLE:
                st.success(f"ğŸ“‹ JSON + PDF Mode ({PDF_METHOD})")
                st.info("AI ÏˆÎ¬Ï‡Î½ÎµÎ¹ ÏƒÎµ ÎµÏ€Î¯ÏƒÎ·Î¼Î± Î­Î³Î³ÏÎ±Ï†Î±")
            else:
                st.success("ğŸ“‹ JSON First Mode")
                st.warning("PDF search Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿")
        else:
            st.warning("ğŸ“š JSON Only Mode")
            if GROQ_AVAILABLE:
                st.info("Î“Î¹Î± AI+PDF, Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Groq API key")
            else:
                st.error("Groq library Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î·")

        st.markdown("---")

        if st.button("ğŸ—‘ï¸ ÎÎ­Î± Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

        # Enhanced Technical Information
        if st.checkbox("ğŸ”§ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚"):
            st.markdown("**Î“Î¹Î± Ï„ÎµÏ‡Î½Î¹ÎºÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±:**")
            st.markdown("ğŸ“§ gbouchouras@mitropolitiko.edu.gr")
            
            # Enhanced debugging info
            st.write("**System Status:**")
            st.write("â€¢ Response Priority: JSON â†’ PDF â†’ General AI â†’ JSON Fallback")
            st.write("â€¢ Groq Available:", GROQ_AVAILABLE)
            st.write("â€¢ Groq Client:", st.session_state.chatbot.groq_client is not None)
            st.write("â€¢ PDF Available:", PDF_AVAILABLE)
            if PDF_AVAILABLE:
                st.write("â€¢ PDF Method:", PDF_METHOD)
            st.write("â€¢ QA Data Count:", len(st.session_state.chatbot.qa_data))
            
            # PDF Status
            if PDF_AVAILABLE:
                st.write("**PDF Files:**")
                for filename in st.session_state.chatbot.pdf_files:
                    cached = "ğŸ“‹" if filename in st.session_state.chatbot.pdf_cache else "â³"
                    st.write(f"â€¢ {cached} {filename}")
                
                if st.session_state.chatbot.pdf_cache:
                    total_chars = sum(len(content) for content in st.session_state.chatbot.pdf_cache.values())
                    st.info(f"ğŸ“Š Cached PDF content: {total_chars:,} characters")
            else:
                st.error("ğŸ“„ PDF processing disabled")
                st.info("ğŸ’¡ Install: pip install PyPDF2")
            
            # File status
            qa_file_exists = os.path.exists("qa_data.json")
            st.write("â€¢ qa_data.json exists:", qa_file_exists)
            
            if qa_file_exists:
                try:
                    with open("qa_data.json", 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                    st.success(f"ğŸ“„ External JSON: {len(file_data)} entries loaded")
                    st.write(f"â€¢ Entry IDs: {[d['id'] for d in file_data[:5]]}")
                    if len(file_data) > 5:
                        st.write(f"â€¢ ... and {len(file_data)-5} more")
                    
                    # File info
                    file_size = os.path.getsize("qa_data.json")
                    mtime = os.path.getmtime("qa_data.json")
                    last_modified = datetime.datetime.fromtimestamp(mtime).strftime("%d/%m/%Y %H:%M")
                    st.info(f"ğŸ“Š File size: {file_size:,} bytes")
                    st.info(f"ğŸ•’ Last modified: {last_modified}")
                    
                except Exception as e:
                    st.error(f"âŒ JSON Error: {e}")
            else:
                st.warning("ğŸ“‹ Using fallback data")
                st.error("ğŸ’¡ Create qa_data.json with 39 entries!")
            
            # Directory info
            st.write("**File System:**")
            st.write("â€¢ Current dir:", os.getcwd())
            files = [f for f in os.listdir('.') if f.endswith('.json')]
            st.write("â€¢ JSON files:", files if files else "None found")
            
            # Categories info
            if st.session_state.chatbot.qa_data:
                categories_count = {}
                for qa in st.session_state.chatbot.qa_data:
                    cat = qa.get('category', 'Unknown')
                    categories_count[cat] = categories_count.get(cat, 0) + 1
                
                st.write("**Categories:**")
                for cat, count in categories_count.items():
                    st.write(f"â€¢ {cat}: {count}")

    # Chat interface
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    st.markdown("### ğŸ’¬ ÎšÎ¬Î½Ï„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚")

    # Display chat messages
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f'<div class="user-message"><strong>Î•ÏƒÎµÎ¯Ï‚:</strong> {message["content"]}</div>', unsafe_allow_html=True)
        else:
            # Convert markdown to HTML for better display
            content = message["content"].replace('\n', '<br>')
            st.markdown(f'<div class="ai-message"><strong>ğŸ¤– Assistant:</strong><br><br>{content}</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)

    # Chat input - moved outside container for better functionality
    user_input = st.chat_input("Î“ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚ ÎµÎ´Ï...")
    
    if user_input:
        # Add user message
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # Get chatbot response
        with st.spinner("Î£ÎºÎ­Ï†Ï„Î¿Î¼Î±Î¹..."):
            try:
                response = st.session_state.chatbot.get_response(user_input)
            except Exception as e:
                response = f"Î£Ï…Î³Î³Î½ÏÎ¼Î·, Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î±: {str(e)}"
                st.error(f"Î£Ï†Î¬Î»Î¼Î±: {e}")
        
        # Add assistant response
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        # Rerun to display new messages
        st.rerun()

    # Footer
    footer_text = "JSON-First + PDF AI Assistant" if PDF_AVAILABLE else "JSON-First AI Assistant"
    st.markdown(f"""
    <div style="text-align: center; color: #6c757d; padding: 1rem;">
        <small>
            ğŸ“ <strong>ÎœÎ·Ï„ÏÎ¿Ï€Î¿Î»Î¹Ï„Î¹ÎºÏŒ ÎšÎ¿Î»Î»Î­Î³Î¹Î¿ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·Ï‚</strong> | 
            Î¤Î¼Î®Î¼Î± Î ÏÎ¿Ï€Î¿Î½Î·Ï„Î¹ÎºÎ®Ï‚ & Î¦Ï…ÏƒÎ¹ÎºÎ®Ï‚ Î‘Î³Ï‰Î³Î®Ï‚<br>
            <em>{footer_text}</em>
        </small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()